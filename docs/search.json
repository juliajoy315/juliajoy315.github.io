[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi! My name is Julia Joy."
  },
  {
    "objectID": "posts/GoalSetting/index.html",
    "href": "posts/GoalSetting/index.html",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "Julia Joy\n\n\nThe knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nI think that the areas that i would most like to focus on are primarily the Implementation. I always feel like more practice with effective coding and learning how to use new tools is so invaluable, I am excited to continue that in this course, especially with all the different kinds of Machine Learning algorithms and models. I am also interested in the Theory aspect as a mathematics minor, I love learning about the numbers and formulas that go behind the operations we can take for granted when we code. I never took multi-calculus (I know, odd for a math minor), so while I think it will be a bit challenging to dredge up my calc and linear algebra since I took those courses so long ago, I think it will be rewarding and fun to expand my knowledge.\n\n\n\n\n\nMost blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\nI think blog posts will be pretty crucial to my learning in this course. Already with the first blog post and working on the second, I enjoy taking the content we discuss in class and applying it on my own. I have always felt like a hands-on learning style fits me the best. Ideally I would like to have a “Satisfactory/No Revision Required” rating on 5-6 of my of my blog posts, and perhaps completing more (I want to complete at least around 60-80% of blog posts) but leaving some space for some blog posts to remain in the “needs revision category”. I have realized that I am someone who is very driven by interest when it comes to coursework. Assignments I enjoy are fun little challenges for me, and I will spend hours working and tweaking them to my satisfiability even when they’re already probably pass the threshold of “good enough” grade wise. But assignments with content that I am not as passionate or interested about can be really hard for me to motivate to spend extra time on, so I would enjoy leaving some space for myself to say “no I think that is good enough for me. I tried it out and am satisfied with my work.”. I aim to give myself about 1-1.5 weeks for a fresh first-draft submission of each blog post I do, just to keep myself on a semi-timeline to ensure nothing gets crammed in at the end. With revision, I think that will be more dependent on extra time I have each week, spending more time on it in the weeks I have a bit more extra time and vice versa, I will allow myself less of a set timeline with those.\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\nI strive to attend every class, with the exception of one to two when it is truly necessary to miss class, such as if I’m sick, have to be out of town for some reason, or if my mental health gets in the way of my academics. In our two weeks of class, I have already gained an appreciation for the daily warmups. I find myself actually spending a good chunk of time on them before class, but I feel like it really does benefit me. The warmups prep me and lay a groundwork for either just basic understanding for the subject we tackle in that class, or in the application of what we’re about to talk about. I aim to complete every warmup prior to class this semester, with the leeway of one or two because life does happen. Outside of completing each warmup, whenever we are in our small groups, I aim to be very involved and ask questions and offer suggestions/solutions to whoever is the warmup presenter. I hope to complete most of the course readings, using it as more of a supplement to my hands on learning. Additionally, I notice that I frequently find it challenging to speak up in class, especially in a large class full of many people who are not only my peers but also my friends. The warmups in small groups help ease the transition before I potentially have to speak in front of the whole class. While I do still find it a bit intimidating, I really appreciate and value being able to talk the problems out in a smaller group setting before a larger one. Peer help/TA/office hours have long time been my favorite way to address questions or concepts I have a hard time grasping, so I expect to attend those when the need strikes. I have realized I am much more of a ask-questions-in-person kind of person than a slack questions user, so while I will check the slack and at some point probably use it to send a chat myself, I do not expect frequent use of it for myself. I think study groups will be big for me this semester, as I am familiar with many people in this course, so I think that will also be beneficial in my learning if I get stuck anywhere and help hours are immediately around.\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\nI am excited about this project as I feel like it will allow me to explore what machine learning can be in an area that I’m a bit more interested in, whatever that may be. Without knowing exactly what my project will look like or be about I cannot detail my goals in that way, however I know some general ideas of what I would like to accomplish. I would like to complete all project milestones on time to keep myself and the group accountable in our semester time frame, contribute to the project in an equal manner including in the algorithm implementation and project presentation, and do what I can to be a great group project partner. I think that everyone has strengths and weaknesses, and for example while I don’t think that I’m the best at writing automated checks for algorithms written by others, I have other skills to offer. I think that is the most important thing about working in a team, to acknowledge everyone’s weaknesses and capitalize on peoples strengths."
  },
  {
    "objectID": "posts/GoalSetting/index.html#what-youll-learn",
    "href": "posts/GoalSetting/index.html#what-youll-learn",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "The knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nI think that the areas that i would most like to focus on are primarily the Implementation. I always feel like more practice with effective coding and learning how to use new tools is so invaluable, I am excited to continue that in this course, especially with all the different kinds of Machine Learning algorithms and models. I am also interested in the Theory aspect as a mathematics minor, I love learning about the numbers and formulas that go behind the operations we can take for granted when we code. I never took multi-calculus (I know, odd for a math minor), so while I think it will be a bit challenging to dredge up my calc and linear algebra since I took those courses so long ago, I think it will be rewarding and fun to expand my knowledge."
  },
  {
    "objectID": "posts/GoalSetting/index.html#what-youll-achieve",
    "href": "posts/GoalSetting/index.html#what-youll-achieve",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "Most blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\nI think blog posts will be pretty crucial to my learning in this course. Already with the first blog post and working on the second, I enjoy taking the content we discuss in class and applying it on my own. I have always felt like a hands-on learning style fits me the best. Ideally I would like to have a “Satisfactory/No Revision Required” rating on 5-6 of my of my blog posts, and perhaps completing more (I want to complete at least around 60-80% of blog posts) but leaving some space for some blog posts to remain in the “needs revision category”. I have realized that I am someone who is very driven by interest when it comes to coursework. Assignments I enjoy are fun little challenges for me, and I will spend hours working and tweaking them to my satisfiability even when they’re already probably pass the threshold of “good enough” grade wise. But assignments with content that I am not as passionate or interested about can be really hard for me to motivate to spend extra time on, so I would enjoy leaving some space for myself to say “no I think that is good enough for me. I tried it out and am satisfied with my work.”. I aim to give myself about 1-1.5 weeks for a fresh first-draft submission of each blog post I do, just to keep myself on a semi-timeline to ensure nothing gets crammed in at the end. With revision, I think that will be more dependent on extra time I have each week, spending more time on it in the weeks I have a bit more extra time and vice versa, I will allow myself less of a set timeline with those.\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\nI strive to attend every class, with the exception of one to two when it is truly necessary to miss class, such as if I’m sick, have to be out of town for some reason, or if my mental health gets in the way of my academics. In our two weeks of class, I have already gained an appreciation for the daily warmups. I find myself actually spending a good chunk of time on them before class, but I feel like it really does benefit me. The warmups prep me and lay a groundwork for either just basic understanding for the subject we tackle in that class, or in the application of what we’re about to talk about. I aim to complete every warmup prior to class this semester, with the leeway of one or two because life does happen. Outside of completing each warmup, whenever we are in our small groups, I aim to be very involved and ask questions and offer suggestions/solutions to whoever is the warmup presenter. I hope to complete most of the course readings, using it as more of a supplement to my hands on learning. Additionally, I notice that I frequently find it challenging to speak up in class, especially in a large class full of many people who are not only my peers but also my friends. The warmups in small groups help ease the transition before I potentially have to speak in front of the whole class. While I do still find it a bit intimidating, I really appreciate and value being able to talk the problems out in a smaller group setting before a larger one. Peer help/TA/office hours have long time been my favorite way to address questions or concepts I have a hard time grasping, so I expect to attend those when the need strikes. I have realized I am much more of a ask-questions-in-person kind of person than a slack questions user, so while I will check the slack and at some point probably use it to send a chat myself, I do not expect frequent use of it for myself. I think study groups will be big for me this semester, as I am familiar with many people in this course, so I think that will also be beneficial in my learning if I get stuck anywhere and help hours are immediately around.\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\nI am excited about this project as I feel like it will allow me to explore what machine learning can be in an area that I’m a bit more interested in, whatever that may be. Without knowing exactly what my project will look like or be about I cannot detail my goals in that way, however I know some general ideas of what I would like to accomplish. I would like to complete all project milestones on time to keep myself and the group accountable in our semester time frame, contribute to the project in an equal manner including in the algorithm implementation and project presentation, and do what I can to be a great group project partner. I think that everyone has strengths and weaknesses, and for example while I don’t think that I’m the best at writing automated checks for algorithms written by others, I have other skills to offer. I think that is the most important thing about working in a team, to acknowledge everyone’s weaknesses and capitalize on peoples strengths."
  },
  {
    "objectID": "posts/WIDS Conference/index.html",
    "href": "posts/WIDS Conference/index.html",
    "title": "WiDS Conference at Middlebury College",
    "section": "",
    "text": "In this blog post, I reflect on my experiences reading ‘Solving the Equation: The Variables for Women’s Success in Engineering and Computing’ by Corbett and Hill (2015) and attending the Women in Data Science conference. Through the two of these experiences, I gained valuable insights into the challenges and potential solutions surrounding gender diversity in STEM fields. I learned about the systemic barriers that hinder women’s ability to enter, continue, and succeed in engineering and computing, that highlight the importance of proactive strategies to equalize representation of women in STEM. This blog post outlines these learnings by reflecting on questions from ‘Solving the Equation: The Variables for Women’s Success in Engineering and Computing’ as well as summarizing the speakers from the Women in Data Science conference."
  },
  {
    "objectID": "posts/WIDS Conference/index.html#part-1-why-spotlight-women-in-data-science",
    "href": "posts/WIDS Conference/index.html#part-1-why-spotlight-women-in-data-science",
    "title": "WiDS Conference at Middlebury College",
    "section": "Part 1: Why Spotlight Women in Data Science?",
    "text": "Part 1: Why Spotlight Women in Data Science?\nIn ‘Solving the Equation: The Variables for Women’s Success in Engineering and Computing’ by Corbett and Hill (2015), the authors show that women are underrepresented in computing, math, and engineering. But why is it a problem? And for whom is it a problem?\nThis underrepresentation of women significant challenges on multiple fronts. This underrepresentation reflects systemic inequalities and biases that have been shown to hinder equal opportunities for women in these fields. By not teaching everyone that women can hold their own and be equally as good in STEM fields as men, women lose out on these high-quality job opportunities. This is not just a problem for women. By a lack of women in computing, math, and engineering, it not only deprives women of potential career paths, but it also limits the diversity of perspectives and talents that are crucial for solving problems, developing rounded mechanisms, and field innovation. As Corbet and Hill said, “The United States simply can’t afford to ignore the perspectives of half the population in future engineering and technical designs”. Gender biases that contribute to the underrepresentation of women in computing, math, and engineering also create obstacles for the men who work alongside women in these industries. Studies point to a devaluation of work when men work with women (West et al., 2012), which can lead to men traking steps to avoid wokring with women, worsening the challenges facing women in male-dominated fields and contributing to the problem. Everyone must work together to help balance the gender representation in computing, math, and engineering, as it is a problem that affects us all no matter our identity.\n\nWhich of the barriers and unequal challenges described in the section “Why So Few?” can be eroded by events that spotlight the achievement of women in STEM?\nThe section “Why so Few?” outlines various barriers and unequal challenges women face in the STEM field, such as sense of belonging, stereotypes and stereotype threat, challenging academic workspaces, as well as isolation. Women may face negative impacts such as experiencing difficultly balancing expected gendered home responsibilities and the culture of overwork, feel de-incentivized by the engineering culture of disengagement as studies show women are more likely than men to express a preference for work with a clear social purpose (Konrad et al., 2000), or feel isolated as significant portion of women reported feeling as if they lacked role models and mentors and did not agree with the statement that “it is safe to speak up most of the time”. While not all of these barriers or challenges can be eroded by events that spotlight the achievement of women in STEM, there are a few that can benefit from these events. What stood out most notably to me that could be benefited by these events was improving the sense of belonging for women in STEM. Events that spotlight the achievement of women in STEM can help increase the sense of belonging for women in STEM, and can have a positive domino-effect in doing so. Events that spotlight the achievement of women in STEM shows examples of women in a historically male-dominated field, helping combat both internalized and external stereotypes. These events show women that success in STEM is possible, providing role models and mentors, which was also noted as a problem for women in the industry. Achievement spotlight events are thus crucial for increasing women’s sense of belonging and increasing the number of women in STEM.\n\n\nPart 2: Attending the Women in Data Science Conference. Yay!\nBy attending the Women in Data Science Conference, I had an unique opportunity to engage with and hear from real professional women that have succeeded against all of the challenges in a male-dominated field, learning about their work as well as their experiences."
  },
  {
    "objectID": "posts/MidCourseEvals/index.html",
    "href": "posts/MidCourseEvals/index.html",
    "title": "CSCI 0451: Mid-Course Reflection",
    "section": "",
    "text": "Julia Joy\n\n\n\n\n\n*How often have you attended class? I have attended every class except for 1.\nHow often have you taken notes on the core readings ahead of the class period? I always read the readings, but I probably take notes on them maybe 1/2-1/3 of the time?\nHow often have you been prepared to present the daily warm-up exercise to your team, even if you weren’t actually called? Almost always, probably with the exception of 1 or 2 times.\nHow many times have you actually presented the daily warm-up to your team? I cant quite remember, maybe 3 or 4?\nHow many times have you asked your team for help while presenting the daily warm-up? I think for 1 part of a problem once.\nHow often have you learned something new from a teammate’s presentation of the daily warm-up? I feel like I can frequently learn a little something new, even if I did the warmup correctly it is always informational to see other approaches or when we were having more discussion-based warmups I learned other perspectives to see things.\nHow often have you helped a teammate during the daily warm-up presentation? Once or twice but we always contribute to each other.\n\n\n\n\n\nHow often have you attended Student Hours or Peer Help? I have not attended Student Hours.\nHow often have you asked for or received help from your fellow students? I have a lot of friends in the class so we often meet together in a study group, so I probably ask someone a question around once a week whether its about the warmups, blog posts, or general clarification of things were supposed to be doing.\nHave you been regularly participating in a study group outside class? Yes.\nHow often have you posted questions or answers in Slack? I have maybe posted one question.\n\n\n\n\n\nHow many blog posts have you submitted? I have submitted 3 blog posts and am currently working on 2 more.\nHow many of your submitted blog posts are at each of the following feedback stages?\n\nE: No revisions suggested: 1\nM: Revisions useful: 2\nR: Revisions encouraged: 0\nN: Incomplete: 0\n\nRoughly how many hours per week have you spent on this course outside of class? Roughly 9-11 depending on the week.\n\n\n\n\n\nAt the beginning of the course, you may have expressed an interest in focusing a little extra on one or two of the following four categories:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nDid you choose to focus on any of these categories? If so, what have you done in order to pursue your interest?\nIn the beginning, I expressed an interest in the Implementation category, as well as a tentative on in the theory category. I think I have definitely focused in on the Implementation category. I always feel like more practice with effective coding and learning how to use new tools is so invaluable, I feel like I have been able to continue that in this course with the learning of all of our new models like the Perceptron. In general too expanding my coding skills by getting more familiar with python and different packages like torch. I am excited to continue with more different kinds of Machine Learning algorithms and models! However for the theory category, I do not think I really would like to focus in on the category as much as I originally thought. I forgot how long it had been since I took linear algebra my freshman year, and I have never taken multi-variable calculus. I can obviously handle differentiation, and my mathematical knowledge/general understanding is definitely not lacking, but I realized that I have less interest in intense mathematical descriptions of frameworks and algorithms, I enjoy my little problem sets more. Thus I do not think I will be choosing to focus in on the Theory category that much anymore. I will focus more into the Implementation category as I have been. Our third(?) week in the semester too maybe me more interested in the social responsibility side of machine learning algorithms, so potentially it would be interesting to conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm for my final project? We shall see!\n\n\n\nFor each of the categories below, replace the “[your response here]” cell with 1-2 paragraphs in which you reflect on the following questions:\n\nIn what ways are you on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what you are doing in order to meet it.\nIn what ways are you not on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what gap you see between where you are and your goal.\nIf there’s any context you want to share about how you are faring relative to your goals, please do!\n\n\n\nIn my original goal setting, I aimed to have a “Satisfactory/No Revision Required” rating on 5-6 of my of my blog posts, and perhaps completing more (I want to complete at least around 60-80% of blog posts) but leaving some space for some blog posts to remain in the “needs revision category”.”\nI hadn’t looked closely enough at the way blog posts were graded yet I guess, because now I know there are two categories that could satisfy that first part of my blog post goals: E: No revisions suggested: and M: Revisions useful:*. Ideally all would be E’s, but I think I will leave the space for 1-2 blog posts to remain in the M category, as I have recieved enough feedback at this point to understand the difference between an E and M blog post, and that stays in accordance with my goals. Additionally in the second part of my goals for blog posts I said I want to complete around 60-80% of blog posts. After getting through half of the semester, I can understand now that completing 80% of the blog posts is simply out of reach for me in this class, especially as we approach our final projects starting. I also did not realize until after my goal setting that some weeks there would be 2 blog posts that could be completed, so that puts it more in perspective as well as I would only choose 1 of 2 options to complete and not both. I think my goal of completing roughly 60% of blog posts is good, as it is also in accordance with the number of 5-6 solid good work blog posts.\nCurrently I have completed 3 blog posts (E,M,M), and have 2 more underway. There have been a total of 7 blog posts out that we could complete, so I am also doing well in my aim of a 60% completion ratio.\nI think that in my goals for the blog posts, I am generally on track to meet my goals from the beginning of the course! I will say that in my goal setting I did mention that ideally it would take me 1-1.5 weeks to complete a blog post and I have struggled to keep up with that timeline, due to other classwork and the fact that I find myself spending considerable amounts of time to thoroughly understand the warmups. I am trying to get better at this timeline, and I think after this week and my 2 in progress blog posts, I will be able to stick to the timeline better. I do think I place more importance in the actual progress of the blog posts rather than the speed at which I turn them in, so I think all should be well for my blog post goals!\n\n\n\nOverall, I definitely think I am on track and acting in accordance with my course presence/participation goals I set.\nI have missed 1 class due to sickness, so I am still very much in line with my goal to attend nearly every class unless truly having to miss it (like when I was sick) or with the personal exception of 2/3 absences. In my goal setting I had aimed to complete every warmup before class and I can happily and proudly say that I have done so for every class period in the semester so far! So my leeway of one or two missed warmups is still very much intact as well. I have also stuck in line of my goals of doing most of the course readings as well as thoroughly participating in our small warmup groups. I have yet to attend peer hours, but I have attended office hours a few times when the need struck which is what I expected and set as an outline for myself. I was right in my guessing that I would not be the biggest slack user, but I have asked all the questions I needed answered in some form or another which is good. Study groups have been big for me this semester too, since I know a good amount of people in the course and find it helpful to talk out some problems I run into, or to confirm things we discuss in class.\nI do think I struggle to raise my hand to answer questions in class, my shyness outweighing everything else. It is something I have tried to work on for a long time, so I have a continued awareness for it in this class as well.\n\n\n\nWe still have not started the final project yet, although the project proposal brainstorming is due on Tuesday (as I write this on Friday), so I still do not have super concrete goals for my project. I have the same goals as before, “I would like to complete all project milestones roughly on time to keep myself and the group accountable in our semester time frame, contribute to the project in an equal manner including in the algorithm implementation and project presentation, and do what I can to be a great group project partner.”, and I do think I will be able to stick in accordance with those goals as our project approaches. This weekend I need to brainstorm what I would like to do for our final project. I think that studying a complex data set in depth, or conducting a series of experiments related to assessing algorithmic bias in a certain class of algorithm interests me more than implementing a new algorithm. However I will also draw inspiration from other peoples project pitches and who knows maybe I will discover something new and interesting to focus in on for our final project.\n\n\n\nIs there anything else that you want to share with me about what you have learned, how you have participated, or what you have achieved in CSCI 0451?\nNot that I can think of right now!\n\n\n\nFrom your experience in CSCI 0451 and your other classes this semester, you may feel moved to make modifications to your goals. Are they still feasible? Too ambitious? Not ambitious enough? If you would like to revise any of your goals from your reflective goal-setting, you can do so below. For each goal you want to modify:\n\nClearly state what the goal was.\nClearly state how you’ve done on that goal so far.\nClearly state your proposed revised goal for the remainder of the course.\n\nI think I have lightly done this throughout this course evaluation and reflection process, but here are the alterations stated plainly.\n\nI had stated a tentative focus on the theory category alongside my primary focus of the implementation category. I no longer wish to focus in as much on the theory category, and instead will apply my efforts to my original focus of the implementation category. Maybe even exploring the social responsibility side of machine learning algorithms in the form of a final project? I did find those weeks of discussion quite interesting, but this is more up to how the final project brainstorming go and if I find my interest sparked by anything.\nIn my original goal of completing 60%-80% of blog posts, after half a semester and a more thorough understanding of how many blog posts we are assigned to be able to do, completing 80% of blog posts is not achievable for me. So I will stick with the lower limit of 60%, or aka 5-6 blog posts.\n\n\n\n\n\nTake 15 minutes to look back on your responses in each of the sections above. Then, state the letter grade that you feel reflects your learning, participation, and achievement in CSCI 0451 so far, and contextualize it against some of the soundbytes below.\n\n\nAn A sounds like:\n\n“I am very proud of my time in this course.”\n“I have grown significantly in multiple ways that matter to me.”\n“I am ready to take the theory, techniques, and ideas of this course into my future classes, projects, hobbies, or career.”\n\nA B sounds like:\n\n“I had some opportunities to learn more, overall I feel good about my time in this course.”\n“I am able to explain some new things or achieve new tasks.”\n“I can see a few ideas from this course that will be relevant for my future classes, projects, hobbies, or career.”\n\nA C sounds like:\n\n“I often made a good effort, but I missed many opportunities to get more out of my time in this course.”\n“I might be able to complete some new tasks related to the course content, but only with significant further guidance.”\n“I don’t see any ways to take the contents of this course into my future classes, projects, hobbies, or career.”\n\nYou might find that some of these soundbytes resonate and other’s don’t! Take some time, see what feels right, and don’t be afraid to celebrate your achievements.\n\nUpon reflection, I feel that my learning, participation, and achievement in CSCI 0451 (so far) are best reflected by a grade of A\n\n\nA way in which I resonate with the soundbytes for that grade above is… - I am proud of my time in this course. - I am ready to take the techniques and ideas of this course into my future. - I have acted in accordance with my goals I set for myself at the beginning of the semester.\n\nUpon completing this mid-course reflection and evaluation, I am very proud that I have stuck in accordance with my goals. I feel that I have acted as a hard-working student in this course, barely deviating from any goals and putting in the time and work that I wanted to see myself do in this class. For these reasons I feel like my learning participation and achievement in CSCI 0451 so far are best reflected by a grade of A. I hope to stick in accordance with my goals for the remainder of the semester and as our final project approaches.\n\n\n\n\nYou may feel disappointed by your reflection. Sometimes we don’t achieve all our goals – it happens and it’s normal! If you are feeling disappointed by how you’ve learned, participated, or achieved in CSCI 0451, then feel free to write something about that below. Feel free to just write your feelings. If you have ideas for how to move forward, include those too! We’ll talk.\n[your response here]"
  },
  {
    "objectID": "posts/MidCourseEvals/index.html#the-data",
    "href": "posts/MidCourseEvals/index.html#the-data",
    "title": "CSCI 0451: Mid-Course Reflection",
    "section": "",
    "text": "*How often have you attended class? I have attended every class except for 1.\nHow often have you taken notes on the core readings ahead of the class period? I always read the readings, but I probably take notes on them maybe 1/2-1/3 of the time?\nHow often have you been prepared to present the daily warm-up exercise to your team, even if you weren’t actually called? Almost always, probably with the exception of 1 or 2 times.\nHow many times have you actually presented the daily warm-up to your team? I cant quite remember, maybe 3 or 4?\nHow many times have you asked your team for help while presenting the daily warm-up? I think for 1 part of a problem once.\nHow often have you learned something new from a teammate’s presentation of the daily warm-up? I feel like I can frequently learn a little something new, even if I did the warmup correctly it is always informational to see other approaches or when we were having more discussion-based warmups I learned other perspectives to see things.\nHow often have you helped a teammate during the daily warm-up presentation? Once or twice but we always contribute to each other.\n\n\n\n\n\nHow often have you attended Student Hours or Peer Help? I have not attended Student Hours.\nHow often have you asked for or received help from your fellow students? I have a lot of friends in the class so we often meet together in a study group, so I probably ask someone a question around once a week whether its about the warmups, blog posts, or general clarification of things were supposed to be doing.\nHave you been regularly participating in a study group outside class? Yes.\nHow often have you posted questions or answers in Slack? I have maybe posted one question.\n\n\n\n\n\nHow many blog posts have you submitted? I have submitted 3 blog posts and am currently working on 2 more.\nHow many of your submitted blog posts are at each of the following feedback stages?\n\nE: No revisions suggested: 1\nM: Revisions useful: 2\nR: Revisions encouraged: 0\nN: Incomplete: 0\n\nRoughly how many hours per week have you spent on this course outside of class? Roughly 9-11 depending on the week."
  },
  {
    "objectID": "posts/MidCourseEvals/index.html#what-youve-learned",
    "href": "posts/MidCourseEvals/index.html#what-youve-learned",
    "title": "CSCI 0451: Mid-Course Reflection",
    "section": "",
    "text": "At the beginning of the course, you may have expressed an interest in focusing a little extra on one or two of the following four categories:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nDid you choose to focus on any of these categories? If so, what have you done in order to pursue your interest?\nIn the beginning, I expressed an interest in the Implementation category, as well as a tentative on in the theory category. I think I have definitely focused in on the Implementation category. I always feel like more practice with effective coding and learning how to use new tools is so invaluable, I feel like I have been able to continue that in this course with the learning of all of our new models like the Perceptron. In general too expanding my coding skills by getting more familiar with python and different packages like torch. I am excited to continue with more different kinds of Machine Learning algorithms and models! However for the theory category, I do not think I really would like to focus in on the category as much as I originally thought. I forgot how long it had been since I took linear algebra my freshman year, and I have never taken multi-variable calculus. I can obviously handle differentiation, and my mathematical knowledge/general understanding is definitely not lacking, but I realized that I have less interest in intense mathematical descriptions of frameworks and algorithms, I enjoy my little problem sets more. Thus I do not think I will be choosing to focus in on the Theory category that much anymore. I will focus more into the Implementation category as I have been. Our third(?) week in the semester too maybe me more interested in the social responsibility side of machine learning algorithms, so potentially it would be interesting to conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm for my final project? We shall see!"
  },
  {
    "objectID": "posts/MidCourseEvals/index.html#reflecting-on-goals",
    "href": "posts/MidCourseEvals/index.html#reflecting-on-goals",
    "title": "CSCI 0451: Mid-Course Reflection",
    "section": "",
    "text": "For each of the categories below, replace the “[your response here]” cell with 1-2 paragraphs in which you reflect on the following questions:\n\nIn what ways are you on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what you are doing in order to meet it.\nIn what ways are you not on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what gap you see between where you are and your goal.\nIf there’s any context you want to share about how you are faring relative to your goals, please do!\n\n\n\nIn my original goal setting, I aimed to have a “Satisfactory/No Revision Required” rating on 5-6 of my of my blog posts, and perhaps completing more (I want to complete at least around 60-80% of blog posts) but leaving some space for some blog posts to remain in the “needs revision category”.”\nI hadn’t looked closely enough at the way blog posts were graded yet I guess, because now I know there are two categories that could satisfy that first part of my blog post goals: E: No revisions suggested: and M: Revisions useful:*. Ideally all would be E’s, but I think I will leave the space for 1-2 blog posts to remain in the M category, as I have recieved enough feedback at this point to understand the difference between an E and M blog post, and that stays in accordance with my goals. Additionally in the second part of my goals for blog posts I said I want to complete around 60-80% of blog posts. After getting through half of the semester, I can understand now that completing 80% of the blog posts is simply out of reach for me in this class, especially as we approach our final projects starting. I also did not realize until after my goal setting that some weeks there would be 2 blog posts that could be completed, so that puts it more in perspective as well as I would only choose 1 of 2 options to complete and not both. I think my goal of completing roughly 60% of blog posts is good, as it is also in accordance with the number of 5-6 solid good work blog posts.\nCurrently I have completed 3 blog posts (E,M,M), and have 2 more underway. There have been a total of 7 blog posts out that we could complete, so I am also doing well in my aim of a 60% completion ratio.\nI think that in my goals for the blog posts, I am generally on track to meet my goals from the beginning of the course! I will say that in my goal setting I did mention that ideally it would take me 1-1.5 weeks to complete a blog post and I have struggled to keep up with that timeline, due to other classwork and the fact that I find myself spending considerable amounts of time to thoroughly understand the warmups. I am trying to get better at this timeline, and I think after this week and my 2 in progress blog posts, I will be able to stick to the timeline better. I do think I place more importance in the actual progress of the blog posts rather than the speed at which I turn them in, so I think all should be well for my blog post goals!\n\n\n\nOverall, I definitely think I am on track and acting in accordance with my course presence/participation goals I set.\nI have missed 1 class due to sickness, so I am still very much in line with my goal to attend nearly every class unless truly having to miss it (like when I was sick) or with the personal exception of 2/3 absences. In my goal setting I had aimed to complete every warmup before class and I can happily and proudly say that I have done so for every class period in the semester so far! So my leeway of one or two missed warmups is still very much intact as well. I have also stuck in line of my goals of doing most of the course readings as well as thoroughly participating in our small warmup groups. I have yet to attend peer hours, but I have attended office hours a few times when the need struck which is what I expected and set as an outline for myself. I was right in my guessing that I would not be the biggest slack user, but I have asked all the questions I needed answered in some form or another which is good. Study groups have been big for me this semester too, since I know a good amount of people in the course and find it helpful to talk out some problems I run into, or to confirm things we discuss in class.\nI do think I struggle to raise my hand to answer questions in class, my shyness outweighing everything else. It is something I have tried to work on for a long time, so I have a continued awareness for it in this class as well.\n\n\n\nWe still have not started the final project yet, although the project proposal brainstorming is due on Tuesday (as I write this on Friday), so I still do not have super concrete goals for my project. I have the same goals as before, “I would like to complete all project milestones roughly on time to keep myself and the group accountable in our semester time frame, contribute to the project in an equal manner including in the algorithm implementation and project presentation, and do what I can to be a great group project partner.”, and I do think I will be able to stick in accordance with those goals as our project approaches. This weekend I need to brainstorm what I would like to do for our final project. I think that studying a complex data set in depth, or conducting a series of experiments related to assessing algorithmic bias in a certain class of algorithm interests me more than implementing a new algorithm. However I will also draw inspiration from other peoples project pitches and who knows maybe I will discover something new and interesting to focus in on for our final project.\n\n\n\nIs there anything else that you want to share with me about what you have learned, how you have participated, or what you have achieved in CSCI 0451?\nNot that I can think of right now!\n\n\n\nFrom your experience in CSCI 0451 and your other classes this semester, you may feel moved to make modifications to your goals. Are they still feasible? Too ambitious? Not ambitious enough? If you would like to revise any of your goals from your reflective goal-setting, you can do so below. For each goal you want to modify:\n\nClearly state what the goal was.\nClearly state how you’ve done on that goal so far.\nClearly state your proposed revised goal for the remainder of the course.\n\nI think I have lightly done this throughout this course evaluation and reflection process, but here are the alterations stated plainly.\n\nI had stated a tentative focus on the theory category alongside my primary focus of the implementation category. I no longer wish to focus in as much on the theory category, and instead will apply my efforts to my original focus of the implementation category. Maybe even exploring the social responsibility side of machine learning algorithms in the form of a final project? I did find those weeks of discussion quite interesting, but this is more up to how the final project brainstorming go and if I find my interest sparked by anything.\nIn my original goal of completing 60%-80% of blog posts, after half a semester and a more thorough understanding of how many blog posts we are assigned to be able to do, completing 80% of blog posts is not achievable for me. So I will stick with the lower limit of 60%, or aka 5-6 blog posts."
  },
  {
    "objectID": "posts/MidCourseEvals/index.html#grade-and-goals",
    "href": "posts/MidCourseEvals/index.html#grade-and-goals",
    "title": "CSCI 0451: Mid-Course Reflection",
    "section": "",
    "text": "Take 15 minutes to look back on your responses in each of the sections above. Then, state the letter grade that you feel reflects your learning, participation, and achievement in CSCI 0451 so far, and contextualize it against some of the soundbytes below.\n\n\nAn A sounds like:\n\n“I am very proud of my time in this course.”\n“I have grown significantly in multiple ways that matter to me.”\n“I am ready to take the theory, techniques, and ideas of this course into my future classes, projects, hobbies, or career.”\n\nA B sounds like:\n\n“I had some opportunities to learn more, overall I feel good about my time in this course.”\n“I am able to explain some new things or achieve new tasks.”\n“I can see a few ideas from this course that will be relevant for my future classes, projects, hobbies, or career.”\n\nA C sounds like:\n\n“I often made a good effort, but I missed many opportunities to get more out of my time in this course.”\n“I might be able to complete some new tasks related to the course content, but only with significant further guidance.”\n“I don’t see any ways to take the contents of this course into my future classes, projects, hobbies, or career.”\n\nYou might find that some of these soundbytes resonate and other’s don’t! Take some time, see what feels right, and don’t be afraid to celebrate your achievements.\n\nUpon reflection, I feel that my learning, participation, and achievement in CSCI 0451 (so far) are best reflected by a grade of A\n\n\nA way in which I resonate with the soundbytes for that grade above is… - I am proud of my time in this course. - I am ready to take the techniques and ideas of this course into my future. - I have acted in accordance with my goals I set for myself at the beginning of the semester.\n\nUpon completing this mid-course reflection and evaluation, I am very proud that I have stuck in accordance with my goals. I feel that I have acted as a hard-working student in this course, barely deviating from any goals and putting in the time and work that I wanted to see myself do in this class. For these reasons I feel like my learning participation and achievement in CSCI 0451 so far are best reflected by a grade of A. I hope to stick in accordance with my goals for the remainder of the semester and as our final project approaches."
  },
  {
    "objectID": "posts/MidCourseEvals/index.html#optional-how-to-improve",
    "href": "posts/MidCourseEvals/index.html#optional-how-to-improve",
    "title": "CSCI 0451: Mid-Course Reflection",
    "section": "",
    "text": "You may feel disappointed by your reflection. Sometimes we don’t achieve all our goals – it happens and it’s normal! If you are feeling disappointed by how you’ve learned, participated, or achieved in CSCI 0451, then feel free to write something about that below. Feel free to just write your feelings. If you have ideas for how to move forward, include those too! We’ll talk.\n[your response here]"
  },
  {
    "objectID": "posts/Racial Bias/index.html",
    "href": "posts/Racial Bias/index.html",
    "title": "Dissecting Racial Bias",
    "section": "",
    "text": "Abstract\nThis exploratory analysis aims to replicate the primary findings of Obermeyer et al. in their study of ‘Dissecting racial bias in an algorithm used to manage the health of populations’ (2019). By reproducing various figures, such as Mean Number of Chronic Illnesses by Percentile Risk Score and Total Medical Expenditure vs. Number of Chronic Illnesses, as well as fitting a linear regression model, this analysis aims to determine if there exists substansial disparity between the risk score and medical costs incurred of black and white patients. The findings indicate that there does indeed exists a disparity between both the attributed risk score and the medical costs incurred of the patients by race. The risk score of white patients are higher than their black patient counterparts who have the same number of chronic illnesses. The costs follow a similar pattern, where white patients incur greater medical costs than their black patient counterparts who have the same number of chronic illnesses. Black patients incur approximately 75% of the costs that white patients incur. These finding suggest that black patients are not getting the health care they need, as they are deprioritized with lower risk scores and receiving less needed healthcare as they take on less medical costs.\n\n\nPART A: Data Access\nLoading in the data, I take a preliminary view to understand the meaning of the respective rows and columns.\n\n# load data \nimport pandas as pd\nurl = \"https://gitlab.com/labsysmed/dissecting-bias/-/raw/master/data/data_new.csv?inline=false\"\ndf = pd.read_csv(url)\n\n\ndf.head()\n\n\n\n\n\n\n\n\nrisk_score_t\nprogram_enrolled_t\ncost_t\ncost_avoidable_t\nbps_mean_t\nghba1c_mean_t\nhct_mean_t\ncre_mean_t\nldl_mean_t\nrace\n...\ntrig_min-high_tm1\ntrig_min-normal_tm1\ntrig_mean-low_tm1\ntrig_mean-high_tm1\ntrig_mean-normal_tm1\ntrig_max-low_tm1\ntrig_max-high_tm1\ntrig_max-normal_tm1\ngagne_sum_tm1\ngagne_sum_t\n\n\n\n\n0\n1.987430\n0\n1200.0\n0.0\nNaN\n5.4\nNaN\n1.110000\n194.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n7.677934\n0\n2600.0\n0.0\n119.0\n5.5\n40.4\n0.860000\n93.0\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n4\n3\n\n\n2\n0.407678\n0\n500.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0.798369\n0\n1300.0\n0.0\n117.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n17.513165\n0\n1100.0\n0.0\n116.0\nNaN\n34.1\n1.303333\n53.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n\n\n\n\n5 rows × 160 columns\n\n\n\n\n\nPART B: Reproducing Figure 1\n\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n\nblackDF= df[df[\"race\"] == \"black\"].copy()\nblackDF['risk_percentile'] = (df['risk_score_t'].rank(pct=True) * 100).round()\nmeanCCblack = blackDF.groupby('risk_percentile')['gagne_sum_t'].transform('mean')\nblackDF['meanCCblack'] = meanCCblack\n\n \nwhiteDF = df[df[\"race\"] == \"white\"].copy()\nwhiteDF['risk_percentile'] = (df['risk_score_t'].rank(pct=True) * 100).round()\nmeanCCwhite = whiteDF.groupby('risk_percentile')['gagne_sum_t'].transform('mean')\nwhiteDF['meanCCwhite'] = meanCCwhite\n\n\n\nsns.scatterplot(x='meanCCblack', y='risk_percentile', data=blackDF, color='teal', label='Black')\nsns.scatterplot(x='meanCCwhite', y='risk_percentile', data=whiteDF, color='orange', label='White')\n\nplt.xlabel('Mean Number of Chronic Illnesses by Percentile Risk Score')\nplt.ylabel('Percentile Risk Score')\nplt.title('Mean Number of Chronic Illnesses')\nplt.legend(title='Race')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nSupposing that Patient A is black and Patient B is white, we can see from the plot, Patient A and Patient B are not equally likely to be referred to the high-risk care management program. Given the same number of active chronic conditions, white patients tend to score higher risk scores compared to their black counterparts. Thus white patients, such as patient A would be more likely to be referred to the high-risk care management program than black patients such as patient B. As Obermeyer et al said, “less-healthy Blacks scored at similar risk scores to more-healthy Whites” and thus there is evidence for “substantial disparities” in the program.\n\n\nPART C: Reproducing Figure 3\n\ndf['risk_percentile'] = (df['risk_score_t'].rank(pct=True) * 100).round()\nriskCostDF = df.groupby(['risk_percentile','race']).aggregate({'cost_t': 'mean'}).reset_index()\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\nsns.scatterplot(x='risk_percentile', y='cost_t', hue = 'race', data=riskCostDF, ax=axes[0])\naxes[0].set_xlabel('Percentile Risk Score')\naxes[0].set_ylabel('Total Medical Expenditure')\naxes[0].set_title('Total Medical Expenditure vs. Percentile Risk Score')\naxes[0].grid(True)\naxes[0].set_yscale('log')\n\nblackDF = df[df[\"race\"] == \"black\"].copy()\nwhiteDF = df[df[\"race\"] == \"white\"].copy()\n\n#second graph \nchronicCostBlack = blackDF.groupby('gagne_sum_t')['cost_t'].mean().reset_index()\nchronicCostWhite = whiteDF.groupby('gagne_sum_t')['cost_t'].mean().reset_index()\n\nsns.scatterplot(x='gagne_sum_t', y='cost_t', data=chronicCostBlack, label =\"White\", ax=axes[1])\nsns.scatterplot(x='gagne_sum_t', y='cost_t', data=chronicCostWhite, label =\"Black\", ax=axes[1])\naxes[1].set_xlabel('Number of Chronic Illnesses')\naxes[1].set_ylabel('Total Medical Expenditure')\naxes[1].set_title('Total Medical Expenditure vs. Number of Chronic Illnesses')\naxes[1].legend(title='Race')\naxes[1].grid(True)\n\nplt.tight_layout(pad=3.0) \nplt.show()\n\n\n\n\n\n\n\n\nFrom the reproduction of these two figures, we can better understand our data. We note that a vast majority of patients in this data set have 5 or fewer chronic conditions. A surprising finding that there exists more disparity in health conditional risk than in costs. However, black patients have lower costs on average than their white patient counterparts, potentially suggesting they are not getting the care they need. To accurately predict costs for patients, their race is crucial information as it distinguishes their predicted costs, this suggests that the relationship between the number of chronic conditions and the cost might be nonlinear.\n\n\nPART D: Modeling Cost Disparity\n\nCostDisparityDF = df[df['gagne_sum_t'] &lt;= 5]\nfiveChronics = CostDisparityDF.shape[0]\ntotalPatientsNum = df.shape[0]\npercentFiveChronics = (fiveChronics / totalPatientsNum) * 100\nprint(percentFiveChronics)\n\n95.53952115447689\n\n\nAbout 95 percent of patients have five or less chronic conditions. Since this is the vast majority of patients, it is justified to focus in on these patients\n\nCostDisparityDF = CostDisparityDF[CostDisparityDF['cost_t'] &gt; 0]\nCostDisparityDF['logCost'] = np.log(CostDisparityDF['cost_t'])\n\nCostDisparityDF['OneHotRace'] = (CostDisparityDF['race'] == 'black').astype(int)\n\n#separate into predictor variables and target variable \npredictorX = CostDisparityDF[['OneHotRace', 'gagne_sum_t']]\ntargetY = CostDisparityDF['logCost']\n\n\n\ntargetY\n\n0        7.090077\n1        7.863267\n2        6.214608\n3        7.170120\n4        7.003065\n           ...   \n48779    6.684612\n48780    7.696213\n48781    6.684612\n48782    7.170120\n48783    8.389360\nName: logCost, Length: 44748, dtype: float64\n\n\nAs indicated in the findings from my figures above, the relationship between the number of chronic conditions and the cost might be nonlinear. Thus in order to fit a linear regression model, we must fit the model with a certain number of polynomial features of active chronic condition in order to to account for the nonlinearity. To determine how many polynomial features should be used for best predictions on this data set, cross validation is needed to test various data sets with differing number of polynomial feature sizes. For each possible polynomial feature size, a LinearRegression model is constructed a cross validation score is computed.\n\ndef add_polynomial_features(X, degree):\n  X_ = X.copy()\n  for j in range(1, degree):\n    X_[f\"poly_{j}\"] = X_[\"gagne_sum_t\"]**j\n  return X_\n\n\nfrom sklearn.linear_model import LinearRegression as LR\nfrom sklearn.model_selection import cross_val_score\n#test each num of active chronic conditions \ncvScores = []\n\nfor degree in range (1,6):\n    X_poly = add_polynomial_features(predictorX, degree)\n    modelToEvaluate = LR()\n    scores = cross_val_score(modelToEvaluate, X_poly, targetY, cv=5, scoring='explained_variance')\n    cvScores.append(np.mean(scores))\n\n    modelToEvaluate.fit(X_poly, targetY)\n\n\ncvScores\n\n[0.08547350567418092,\n 0.08547361170477137,\n 0.08629426236939855,\n 0.08705037980708544,\n 0.08740844467965055]\n\n\n\n#fit the one that is best \npredictorX = add_polynomial_features(predictorX,6)\nfinalModel = LR()\nfinalModel.fit(predictorX, targetY)\nfinalModel.coef_\n\narray([-0.2827181 ,  0.5939195 ,  0.5939195 , -1.28588299,  0.65937337,\n       -0.14306628,  0.01107307])\n\n\nOnce the size of the polynomial feature that is most resonable for this dataset is determined, I fit one last linear regression model with the correct number of polynomial features, which in this case, is all 5.\n\ncostIncurred = np.exp(finalModel.coef_[0])\ncostIncurred\n#0.75\n\n0.7537322331638742\n\n\nFinally, e^W(b) is computed, which represents the cost incurred by black patients as a percentage of white patients. We find this number to be 0.75, which means that black patients incur 75% of the cost that white patients incur. This finding does indeed roughly support the argument of Obermeyer et al. (2019), as Obermeyer et al. claimed that there were opportunites for a disparity wedge to occur between needing health care and receiving health care, claiming that this disparity wedge was found to be correlated with race. Our findings indicate the same thing, since the interpretation of our 75% cost incurred figure could mean that a black patient with the same amount of chronic illnesses as a white patient would be paying less (and thus assumed to be receiving less needed healthcare).\n\n\nPart E: Discussion\nThroughout this exploratory analysis that aimed to replicate the primary findings of Obermeyer et al. in their study of ‘Dissecting racial bias in an algorithm used to manage the health of populations’ (2019), we find similar results and conclusions. By contructing plot figures and linear regression models, I learned that there does indeed exists a disparity between both the attributed risk score and the medical costs incurred of the patients by race. The risk score of white patients are higher than their black patient counterparts who have the same number of chronic illnesses. The costs follow a similar pattern, Black patients incurring approximately 75% of the costs that white patients incur, where both sets of patient counterparts have the same number of chronic illnesses. These finding suggest that black patients are not getting the health care they need, as they are deprioritized with lower risk scores and receiving less needed healthcare as they take on less medical costs. Thus this model violates the fairness measure of error rate parity. The importance of constructing a linear regression model with the proper number of polynomial features was emphasized in this analysis. Additionally, I gained an appreciation for extrapolating findings beyond their face value. Black patients incur less medical costs than their white counterparts with the same number of chronic illnesses. Why? Perhaps because they are not receiving the full extent of the healthcare they need and are thus paying less medical costs.\nWhat aspects of the study support your answer?\nOf the three statistical discrimation criteria discussed in Chapter 3 of Barocas, Hardt, and Narayanan (2023)- error rate parity, acceptance rate parity/independence, and sufficiency (calibration), the criteria that best describes the purported bias of the algorithm studied by Obermeyer et al. (2019) is error rate parity. Barocas, Hardt, and Narayanan (2023) define error rate parity as one of the measures of statistical fairness in which the error rates should be balanced across different groups, such as in this study the error rates should be balanced across different demographic groups. Acceptance rate parity/independence refers to the principle that people with similar qualifications should have equal probabilities of being accepted into a program or receiving a service, while sufficiency (calibration) is the idea that that predicted probabilities of outcomes actually reflect he true likelihood of the events occurring. I believe that error rate parity best describes the purported bias of the algorithm because the algorithm systematically assigns lower risk scores to black patients compared to white patients with the same number of chronic illnesses which can/does lead to unequal treatment and resource allocation in healthcare. This is reflected by the 75% medical costs that Black patients pay compared to their White counterparts. Black patients are getting assigned lower scores and thus pay less for a lesser degress of medical treatment. The aspects of the study that support my answer is Obermeyer et al.’s commentary that this bias is “attributable to label choice—the difference between some unobserved optimal prediction and the prediction of an algorithm trained on an observed label”. They claim that labels can be often measured in an error-prone way that reflect structural inequalities. This model has a problem with error rate parity as it does not make errors at similar rates for different groups to ensure fairness."
  },
  {
    "objectID": "posts/Palmer Penguins/index.html",
    "href": "posts/Palmer Penguins/index.html",
    "title": "Palmer Penguins",
    "section": "",
    "text": "The aim of this exploration of the Palmer Penguins dataset is to gain insight into the dataset through predictive classification. This exploration involves constructing visualizations of the data using seaborn and creating informative summary tables using pandas. By testing various combinations of models through a reproducible process, three key features are able to be identified. Out of the three features, I found that the combination of 1 qualitative feature: Clutch Completion, and 2 quantitative features: Culmen Length and Culmen Depth, were the most effective to reach 100% testing classification accuracy using a Decision Tree Model. The evaluation phase provides a visual representation of the models behavior by showing the decision regions of the trained decision tree model. Through this process, we gain a comprehensive understanding of the Palmer Penguins dataset and demonstrate the effectiveness of a trained decision tree model in accurately classifying Palmer Penguin data.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\nWe can take a peek at the data to get a better idea of where to start, by using .head()\n\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN"
  },
  {
    "objectID": "posts/Palmer Penguins/index.html#figure-findings",
    "href": "posts/Palmer Penguins/index.html#figure-findings",
    "title": "Palmer Penguins",
    "section": "Figure Findings",
    "text": "Figure Findings\nVarious summary tables and visualizations were tested, aiming to determine the most effective presentation of the Palmer Penguins dataset. Initially different grouping criteria and variables were considered, such as species, island, sex, clutch completion, culmen depth and length, body mass, and flipper length. Ultimately I decided to come back and choose the summary table and visualizations that reflected the variables I later found to have the highest predictive accuracy: Culmen Depth, Culmen Length, and Clutch Completion. Summary tables were created using pandas.groupby().aggregate. From the summary tables we observe that among different species, Culmen Length varies to a larger degree than Culmen Depth does. Upon a glance of the summary table, it is hard to see if clutch completion and culmen characteristics are correlated. In the first visualization on the right, we can see the penguins depicted by virtue of the respective culmen length and depth, colored by the Clutch Completion. We observe a relatively uniform distribution of clutch completion- there does not seem to be an immediate observable relationship between the three. My next visualization shows the same axes of Culmen Depth and Length, this time however colored by species. In this figure, we notice clear species groupings, corresponding to their Culmen Depth-Length relationship."
  },
  {
    "objectID": "posts/Palmer Penguins/index.html#find-the-best-features-for-prediction",
    "href": "posts/Palmer Penguins/index.html#find-the-best-features-for-prediction",
    "title": "Palmer Penguins",
    "section": "Find the Best Features for Prediction",
    "text": "Find the Best Features for Prediction\nIn order to ensure our model has the highest classification accuracy possible, we need to select features that are more indicative of the species group a penguin belongs to. By testing every combination of features, we are able to find the three that result in the highest training set accuracy. We find that there are multiple 3-feature sets with 100% training set classification accuracy.\n\nfrom itertools import combinations\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island\"]\nall_quant_cols = ['Flipper Length (mm)','Culmen Length (mm)', 'Culmen Depth (mm)']\n\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = qual_cols + list(pair) \n    print(cols)\n\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Flipper Length (mm)', 'Culmen Length (mm)']\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Flipper Length (mm)', 'Culmen Depth (mm)']\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n['Sex_FEMALE', 'Sex_MALE', 'Flipper Length (mm)', 'Culmen Length (mm)']\n['Sex_FEMALE', 'Sex_MALE', 'Flipper Length (mm)', 'Culmen Depth (mm)']\n['Sex_FEMALE', 'Sex_MALE', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Flipper Length (mm)', 'Culmen Length (mm)']\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Flipper Length (mm)', 'Culmen Depth (mm)']\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n\n\nWe can see that the combinations of variables:\n[‘Clutch Completion_No’, ‘Clutch Completion_Yes’, ‘Flipper Length (mm)’, ‘Culmen Length (mm)’] [‘Clutch Completion_No’, ‘Clutch Completion_Yes’, ‘Flipper Length (mm)’, ‘Culmen Depth (mm)’] [‘Clutch Completion_No’, ‘Clutch Completion_Yes’, ‘Culmen Length (mm)’, ‘Culmen Depth (mm)’] [‘Sex_FEMALE’, ‘Sex_MALE’, ‘Flipper Length (mm)’, ‘Culmen Length (mm)’] [‘Sex_FEMALE’, ‘Sex_MALE’, ‘Flipper Length (mm)’, ‘Culmen Depth (mm)’] [‘Sex_FEMALE’, ‘Sex_MALE’, ‘Culmen Length (mm)’, ‘Culmen Depth (mm)’] [‘Island_Biscoe’, ‘Island_Dream’, ‘Island_Torgersen’, ‘Flipper Length (mm)’, ‘Culmen Length (mm)’] [‘Island_Biscoe’, ‘Island_Dream’, ‘Island_Torgersen’, ‘Flipper Length (mm)’, ‘Culmen Depth (mm)’] [‘Island_Biscoe’, ‘Island_Dream’, ‘Island_Torgersen’, ‘Culmen Length (mm)’, ‘Culmen Depth (mm)’]\nAll result in 100% testing accuracy.\nIn order to narrow these feature-sets down to the single set that will be the most effective and give us not only 100% training set classificaiton accuracy but also 100% testing set classification accuracy, we repeat the process from earlier. Now operating on the testing set, we test each combination of variables that resulted in 100% training accuracy, to see if any combination of the variables also result in 100% testing accuracy. This is done by scoring models built respectively on each combination of variables. We narrow down the 3-feature sets into one final best feature set: Clutch Completion, Culmen Length (mm), and Culmen Depth (mm).\n\n#pretend we're numbering these from 1-9, look at testing accuracy for each one that has 1.0. \n#3 1.0 !!!  ['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n\ntempCols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']\nDT = DecisionTreeClassifier()\nDT.fit(X_train[tempCols], y_train)\nprint(DT.score(X_train[tempCols], y_train))\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\nDT.score(X_test[tempCols], y_test)\n\n1.0\n\n\n1.0\n\n\nWe check our cross-validation score, noting that a cross validation score of 94.5% is indicitive of future model generalizability.\n\n#cross-validation\nfrom sklearn.model_selection import cross_val_score\ncv_scores_DT = cross_val_score(DT, X_train, y_train, cv=5)\ncv_scores_DT.mean()\n\n0.9569381598793363\n\n\n\nPlotting Decision Regions\nFinally, we can visualize these Decision Regions using matplotlib.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\n\n#visualizing decision regions on train set \nplot_regions(DT, X_train[tempCols], y_train)\n\n\n\n\n\n\n\n\n\n#visualizing decision regions on test set\nplot_regions(DT, X_test[tempCols], y_test)\n\n\n\n\n\n\n\n\n\n\nConfusion Matrix\n\n#need to truncate X_test to have only the columns we're using to predict before doing confusion matrix\nX_test = X_test[['Culmen Length (mm)', 'Culmen Depth (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']]\n\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = DT.predict(X_test)\ny_test_pred\n\nC = confusion_matrix(y_test, y_test_pred)\nC\n\narray([[31,  0,  0],\n       [ 0, 11,  0],\n       [ 0,  0, 26]])\n\n\nSince the trained model has 100% training and testing classifcation accuracy, the confusion matrix reflects the lack of classification errors.\n\n\nSummary Discussion\nIn conclusion, this exploration of the Palmer Penguins dataset has provided insights into the dataset through predictive classification. Through the construction of informative summary tables and visually appealing figures, we were able to uncover various patterns, trends, and relationships within the data. By systematically testing different combinations of both qualitative and quantitative features of the Palmer Penguins, I found the best combination of three features that yielded high classification accuracy. One qualitative feature, clutch completion, and two quantitative features, culmen length and culmen depth (mm). By employing scikit-learn’s DecisionTreeClassifier, I trained a model on these features and achieved a classification accuracy of 100% on both the training and testing sets. This shows the importance of feature selection, model selection and evaluation in building accurate predictive models. Through this whole process, I gained a comprehensive understanding of the Palmer Penguins dataset and demonstrate the effectiveness of a trained model in accurately classifying Palmer Penguin data. From this process, I learned how important both the selection of the right features as well as the right model are. I learned that 100% training set classification accuracy does not guarantee 100% testing set classification accuracy, and how it is important to tweak the model to ensure that future uses beyond a training set maintain a high level of accuracy. I gained an appreciation of visualizations as a tool for greater understanding of initial data as well as the effect of models. I feel confident in future endeavors to explore, visualize, and predict data."
  },
  {
    "objectID": "posts/Decision Making/index.html",
    "href": "posts/Decision Making/index.html",
    "title": "Optimal Decision Making",
    "section": "",
    "text": "import pandas as pd\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf_train = pd.read_csv(url)\n\n/var/folders/6v/npbkg9_919s0m2j5qd702gf00000gn/T/ipykernel_10000/516695261.py:1: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n#PART B Visualizations \n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#figure 1 \nplt.figure(figsize=(10, 6))\nsns.countplot(x='person_home_ownership', hue='loan_intent', data=df_train)\nplt.title('Loan Intent vs. Home Ownership Status')\nplt.xlabel('Home Ownership')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\nplt.legend(title='Loan Intent')\nplt.show()\n#figure 2\nageCategory = [20, 30, 40, 50, 60, 70, 80, 90, 100]\ndf_train['ageCategory'] = pd.cut(df_train['person_age'], bins=ageCategory)\nIR = df_train.groupby(['ageCategory']).agg({'loan_int_rate': 'mean'}).reset_index()\nIR = IR.sort_values(by='ageCategory', ascending=True)\nprint(IR)\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x='ageCategory', y='loan_int_rate', data=IR)\nplt.title('Mean Interest Rate by Age Category')\nplt.xlabel('Age Category')\nplt.ylabel('Mean Interest Rate')\nplt.ylim(7, 11.5) \nplt.show()\n\n/var/folders/6v/npbkg9_919s0m2j5qd702gf00000gn/T/ipykernel_10000/3508508793.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  IR = df_train.groupby(['ageCategory']).agg({'loan_int_rate': 'mean'}).reset_index()\n\n\n  ageCategory  loan_int_rate\n0    (20, 30]      10.997363\n1    (30, 40]      11.053365\n2    (40, 50]      11.021150\n3    (50, 60]      11.054049\n4    (60, 70]      11.019730\n5    (70, 80]       9.636000\n6    (80, 90]       7.510000\n7   (90, 100]            NaN\n#summary table\ndfIRSorted = df_train.dropna(subset=['loan_int_rate'])\ndfIRSorted = df_train.sort_values(by='loan_int_rate', ascending=True)\n\nlowest10IR = dfIRSorted[['ageCategory', 'person_home_ownership', 'loan_int_rate']]\nlowest10IR = lowest10IR.head(10).drop_duplicates()\n\nprint(lowest10IR)\n\n      ageCategory person_home_ownership  loan_int_rate\n6061     (20, 30]              MORTGAGE           5.42\n24160    (30, 40]              MORTGAGE           5.42\n15162    (20, 30]                  RENT           5.42\n6383     (20, 30]                   OWN           5.42\n21672    (30, 40]                  RENT           5.42\n###PART C \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import cross_val_score\n\ncleanedData = df_train.dropna()\nfeatureCombos = [\n    ['loan_int_rate', 'loan_percent_income'], \n    ['person_age', 'person_income', 'person_emp_length', 'loan_amnt'],\n    ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income']\n]\n\nfor features in featureCombos:\n    X = cleanedData[features]\n    y = cleanedData['loan_status'] \n\n    model = LogisticRegression(max_iter=1000)\n    model.fit(X, y)\n\n    y_pred = model.predict(X)\n    #print(classification_report(y_test, y_pred))\n    coef = model.coef_\n    print(coef)\n\n    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n    print(\"Cross-validation scores:\", scores)\n\n[[0.28951836 8.41878466]]\nCross-validation scores: [0.82572614 0.82354226 0.82922035 0.81476627 0.82350371]\n[[ 2.26769069e-03 -3.25488772e-05 -3.34182406e-02  1.15567329e-04]]\nCross-validation scores: [0.79537017 0.80061149 0.80082988 0.79663609 0.79750983]\n[[-8.69205819e-04 -1.19666596e-06 -2.07101202e-02 -7.94597482e-05\n   3.13264706e-01  1.09583696e+01]]\nCross-validation scores: [0.83751911 0.83380651 0.83358812 0.82459589 0.83355177]\nimport numpy as np \n\nprobs = model.predict_proba(X)[:, 1]\nthresholds = np.linspace(0, 1, 100)\npotentialAvgProfits = []\n\nfor threshold in thresholds:\n    predictions = probs &gt;= threshold\n    profitPer = np.where(predictions == 1,\n                                   X['loan_amnt'] * (1 + 0.25 * X['loan_int_rate']) ** 10 - X['loan_amnt'],\n                                   X['loan_amnt'] * (1 + 0.25 * X['loan_int_rate']) ** 3 - 1.7 * X['loan_amnt'])\n    \n    avgProfit = profitPer.mean()\n    potentialAvgProfits.append(avgProfit)\n\n\nthreshIndex = np.argmax(potentialAvgProfits)\nbestThresh = thresholds[threshIndex]\nbestAvgProfit = potentialAvgProfits[threshIndex]\nprint(bestThresh)\nprint(bestAvgProfit)\n\n0.0\n31508209740.26809\n#load test set \n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/test.csv\"\ndf_test = pd.read_csv(url)\ncleanedTestData = df_test.dropna()\nX_test = cleanedTestData[features]\n\nprobs = model.predict_proba(X_test)[:, 1]\n\nfor threshold in thresholds:\n    predictions = probs &gt;= threshold\n    profitPer = np.where(predictions == 1,\n                                   X_test['loan_amnt'] * (1 + 0.25 * X_test['loan_int_rate']) ** 10 - X_test['loan_amnt'],\n                                   X_test['loan_amnt'] * (1 + 0.25 * X_test['loan_int_rate']) ** 3 - 1.7 * X_test['loan_amnt'])\n    \n    avgProfit = profitPer.mean()\nprint(avgProfit)\n\n611638.5685903775\n#Part F \n\n#SHOULD FIRST ADD IN THE RESULTS OF MY MODEL INTO A NEW TEST DATA SET, evaluateModelData\n\n#Is it more difficult for people in certain age groups to access credit under your proposed system?\nageCategory = pd.cut(df_test['person_age'], bins=[20, 30, 40, 50, 60, 70, 80, 90, 100])\nageCatCounts = df_test.groupby(ageCategory)['loan_status'].count()\nageCatApproved = df_test.groupby(ageCategory)['loan_status'].mean()\n\n#Is it more difficult for people to get loans in order to pay for medical expenses? How does this compare with the actual rate of default in that group? What about people seeking loans for business ventures or education?\napprovalsByLI = df_test.groupby('loan_intent')['NEWCOLUMN'].mean() \ndefaultRates = df_test.groupby('loan_intent')['NEWCOLUMN'].mean()\n\n\n#How does a person’s income level impact the ease with which they can access credit under your decision system?\nincomeCategory = pd.cut(df_test['person_income'], bins=[0, 50000, 100000, 150000, 200000, np.inf])\napprovalsbyInc = df_test.groupby(incomeCategory)['NEWCOLUMN'].mean()  # Proportion of approvals by income level"
  },
  {
    "objectID": "posts/Decision Making/index.html#part-g",
    "href": "posts/Decision Making/index.html#part-g",
    "title": "Optimal Decision Making",
    "section": "Part G",
    "text": "Part G\nConsidering that people seeking loans for medical expense have high rates of default, is it fair that it is more difficult for them to obtain access to credit?\nYou are free to define “fairness” in a way that makes sense to you, but please write down your definition as part of your discussion."
  },
  {
    "objectID": "posts/Decision Making/index.html#conclusion",
    "href": "posts/Decision Making/index.html#conclusion",
    "title": "Optimal Decision Making",
    "section": "Conclusion",
    "text": "Conclusion"
  },
  {
    "objectID": "posts/Perceptron/index.html",
    "href": "posts/Perceptron/index.html",
    "title": "Implementing the Perceptron Algorithm",
    "section": "",
    "text": "In this blog post, I implemented the perceptron algorithm, a fundamental part of many machine learning models. Through a series of visualizations, I demonstrate the behavior of the perceptron algorithm on both linearly separable and non-linearly separable datasets in two dimensions, as well as multi-dimensional feature spaces. Additionally, I implemented the minibatch perceptron, exploring training efficiency compared to the regular perceptron as well as looking at loss convergence behavior. Through this process, I learned the ins and outs of the perceptron algorithm, and how it responds to different types of data.\n\n%load_ext autoreload\n%autoreload 2\nfrom perceptron import Perceptron, PerceptronOptimizer\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload"
  },
  {
    "objectID": "posts/Perceptron/index.html#part-a-perceptron-implementation",
    "href": "posts/Perceptron/index.html#part-a-perceptron-implementation",
    "title": "Implementing the Perceptron Algorithm",
    "section": "Part A: Perceptron Implementation",
    "text": "Part A: Perceptron Implementation\nThe implementation of the perceptron algorithm itself is located in file perceptron.py. In this file I implemented the score, predict, loss, step, and grad functions:\nscore: Computes the scores for each data point in the feature matrix X. The formula for the ith entry of s is s[i] = &lt;self.w, x[i]&gt;, the cross product of the input data and the model weights.\npredict: Calculates y_hat, the predictions for each data point in the feature matrix X. y_hat takes on values of either 1 or 0, where y_hat is assigned 1 if the score &gt;=0 , and y_hat is assigned 0 otherwise.\nloss: Computes the misclassification rate of the model by calculating the mean of all the misclassified data points.\nstep: Compute one update step of the perceptron update using the feature matrix X and target vector y.\ngrad: This function computes the gradient of the empirical risk. If a data point is correctly classified, it returns a gradient of 0. If a data point is misclassified, it returns the gradient of the cross product between the input data and the output.\nIn order to check if this code is correctly working, I must perform experiments on different kinds of data. ## Part B: Experiments\n\nLinearly Separable Data:\nI first visualize the data, to see how the data I am working with is indeed linearly-separable. I run the minimal training loop code from class notes, aiming to end with loss = 0 on linearly separable data.\n\nimport torch\nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\ntorch.manual_seed(12345)\n\ndef perceptron_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n\n    return X, y\n\nX, y = perceptron_data(n_points = 300, noise = 0.2)\n\ndef plot_perceptron_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [-1, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nfig, ax = plt.subplots(1, 1)\nX, y = perceptron_data()\nplot_perceptron_data(X, y, ax)\n\n\n\n\n\n\n\n\nWe can clearly see that the data could be separated by a line, dividing the two classes, orange and blue.\nI then run the minimal training loop, and plot the evolution of the loss function.\n\np = Perceptron() \nopt = PerceptronOptimizer(p)\nloss = 1.0\nlossVec = []\n\nn = X.size()[0]\n\n#terminates only if linearly-separable\nwhile loss &gt; 0: \n    loss = p.loss(X, y) \n    lossVec.append(loss)\n    \n    i = torch.randint(n, size = (1,))\n    x_i = X[[i],:]\n    y_i = y[i]\n    opt.step(x_i, y_i)\n\n\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.figure(figsize=(10, 6))\nplt.plot(lossVec, color = \"slategrey\")\nplt.scatter(torch.arange(len(lossVec)), lossVec, color = \"slategrey\", s=3)\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\nplt.title(f\"Evolution of the Loss Function with Linearly Separable Data\")\n#check final loss value as a means of verifying model \nfinalLossVal = lossVec[len(lossVec)-1]\n\n\n\n\n\n\n\n\nWe can see that the loss decreases after many iterations and eventually reaches 0 when running on this linearly-separable data."
  },
  {
    "objectID": "posts/Perceptron/index.html#non-linearly-separable-data",
    "href": "posts/Perceptron/index.html#non-linearly-separable-data",
    "title": "Implementing the Perceptron Algorithm",
    "section": "Non-Linearly separable Data:",
    "text": "Non-Linearly separable Data:\nWe must first generate some data that we know will not be linearly separable. We can do this by editing code provided by the class notes. Non-linearly separable data means that certain data points are in the space that would normally be considered distinctly one class or another, these points are our overlapping data points.\n\nimport torch\nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\ntorch.manual_seed(1234)\n\ndef overlapPerceptronData(n_points = 300, noise = 0.2, p_dims = 2, numOverlap = 30):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # now generate overlapping points\n    overlappingX = torch.rand(numOverlap, p_dims) * (X.max() - X.min()) + X.min()\n    # add in the overlapping points to the original data points \n    overlappingX = torch.cat((overlappingX, torch.ones((numOverlap, 1))), 1)\n    # generate labels for these new points \n    overlappingy = torch.ones(numOverlap, dtype=torch.bool)\n    X = torch.cat((X, overlappingX), dim=0)\n    y = torch.cat((y, overlappingy), dim=0)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n\n    return X, y\n\nIn order to visualize the now newly-altered, non-linearly separable data, we can plot the data as a scatterplot, also using the class notes.\n\ndef plotOverlap(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [-1, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\n\n\nfig, ax = plt.subplots(1, 1)\nX, y = overlapPerceptronData()\nnonLinPlot = plotOverlap(X, y, ax)\n\n\n\n\n\n\n\n\nWe can see that the overlapping of the data was successful, thus meaning that our data is no longer linearly-separable. Now we can rerun the perceptron algorithm, but since the data is not linearly separable it must be run for a certain number of iterations to ensure that the algorithm terminates. The number of iterations is set to 1000, plenty for the algorithm to run its due course.\n\ntorch.manual_seed(1234)\n\np = Perceptron()\nopt = PerceptronOptimizer(p)\nX, y = overlapPerceptronData()\n\nlossVecNLS = []\n\nfor index in range(0, 1000):\n    \n    i = torch.randint(n, size = (1,))\n    x_i = X[[i],:]\n    y_i = y[i]\n    local_loss = opt.step(x_i, y_i)\n    loss = p.loss(X, y).item()\n    lossVecNLS.append(loss)\n\nfinalWeights = opt.model.w\n\nNow we visualize the evolution of the loss function for a non-linearly separable dataset. We can note that although the loss does decrease over iterations, it never fully reaches 0, unlike the plot of the evolution of the loss function with linearly-separable data.\n\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.figure(figsize=(10, 6))\nplt.plot(lossVecNLS, color = \"slategrey\")\nplt.scatter(torch.arange(len(lossVecNLS)), lossVecNLS, color = \"slategrey\", s=3)\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\nplt.title(f\"Evolution of the Loss Function with Non-Linearly Separable Data\")\n#check final loss value as a means of verifying model \nfinalLossVal = lossVecNLS[len(lossVecNLS)-1]\n\n\n\n\n\n\n\n\nLet’s show the decision boundary in the final iteration, after 1000 runs of the perceptron updates. We can utilize the draw_line function from lecture to do so.\n\n#function from lecture\ndef draw_line(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    l = ax.plot(x, y, **kwargs) \n    fig, ax = plt.subplots(1, 1)\n\nfig, ax = plt.subplots(1, 1)\nplotOverlap(X, y, ax)\ndraw_line(finalWeights, x_min = -2, x_max = 3, ax = ax, color = \"black\", linestyle = \"dashed\")"
  },
  {
    "objectID": "posts/Perceptron/index.html#data-in-more-than-two-dimensions",
    "href": "posts/Perceptron/index.html#data-in-more-than-two-dimensions",
    "title": "Implementing the Perceptron Algorithm",
    "section": "Data in More Than Two Dimensions:",
    "text": "Data in More Than Two Dimensions:\nThe perceptron algorithm is also able to work on data with more than 2 dimensions, in this case the generated data has 5 dimensions. Similarly to how I did before, I rerun the perceptron algorithm, and visualize the evolution of the loss function.\n\nX, y = overlapPerceptronData(n_points = 300, noise = 0.2, p_dims = 5, numOverlap =0)\n\ntorch.manual_seed(12345)\n\n\np = Perceptron()\nopt = PerceptronOptimizer(p)\nX, y = overlapPerceptronData()\nlossVecMD = []\n\nfor index in range(0, 1000):\n    i = torch.randint(n, size = (1,))\n    x_i = X[[i],:]\n    y_i = y[i]\n    local_loss = opt.step(x_i, y_i)\n\n    loss = p.loss(X, y).item()\n    lossVecMD.append(loss)\n\n\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.figure(figsize=(10, 6))\n\nplt.plot(lossVecMD, color = \"slategrey\")\nplt.scatter(torch.arange(len(lossVecMD)), lossVecMD, color = \"slategrey\", s=3)\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\nplt.title(f\"Evolution of the Loss Function with Multiple Dimensions\")\n#check final loss value as a means of verifying model \nfinalLossVal = lossVecMD[len(lossVecMD)-1]\nfinalLossVal\n\n0.05454545468091965\n\n\n\n\n\n\n\n\n\nWe can see that the loss does decrease over the iterations ran, however since the score does not fully reach zero, I believe that the data is not linearly-separable.\n\nPart C: Minibatch Perceptron\nIn order to implement mini-batch updating, the perceptron.grad() method needs to be updated to accept a submatrix (of size k * p) of the feature matrix X. After updating, we can proceed.\n\n\nk = 1\n\nX, y = perceptron_data()\n\ntorch.manual_seed(12345) \np = Perceptron() \nopt = PerceptronOptimizer(p)\nloss = 1.0\nlossVecMinibatch = []\n\nn = X.size()[0]\n\nfor index in range(0, 1000):\n    loss = p.loss(X, y) \n    lossVecMinibatch.append(loss)\n    \n    k = 1 \n    ix = torch.randperm(X.size(0))[:k]\n\n    xSubmatrix = X[ix]\n    ySubmatrix = y[ix]\n\n    # opt step with the random submatrix\n    opt.step(xSubmatrix, ySubmatrix)\n\n\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.figure(figsize=(10, 6))\n\nplt.plot(lossVecMinibatch, color = \"slategrey\")\nplt.scatter(torch.arange(len(lossVecMinibatch)), lossVecMinibatch, color = \"slategrey\", s=3)\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\nplt.title(f\"Evolution of the Loss Function with Multiple Dimensions\")\n#check final loss value as a means of verifying model \nfinalLossVal = lossVecMinibatch[len(lossVecMinibatch)-1]\nfinalLossVal\n\ntensor(0.)\n\n\n\n\n\n\n\n\n\nWhen k = 1, we can see that the mini-batch perceptron performs similarly to the regular perceptron on linearly separable data, as its loss eventually reaches 0.\n\nX, y = overlapPerceptronData()\n\ntorch.manual_seed(12345) \np = Perceptron() \nopt = PerceptronOptimizer(p)\nloss = 1.0\nlossVecMinibatch = []\n\nn = X.size()[0]\n\nfor index in range(0, 1000):\n    loss = p.loss(X, y) \n    lossVecMinibatch.append(loss)\n    \n    k = 1 \n    ix = torch.randperm(X.size(0))[:k]\n\n    xSubmatrix = X[ix]\n    ySubmatrix = y[ix]\n\n    # opt step with the random submatrix\n    opt.step(xSubmatrix, ySubmatrix)\n\n\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.figure(figsize=(10, 6))\n\nplt.plot(lossVecMinibatch, color = \"slategrey\")\nplt.scatter(torch.arange(len(lossVecMinibatch)), lossVecMinibatch, color = \"slategrey\", s=3)\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\nplt.title(f\"Evolution of the Loss Function with Multiple Dimensions\")\n#check final loss value as a means of verifying model \nfinalLossVal = lossVecMinibatch[len(lossVecMinibatch)-1]\nfinalLossVal\n\ntensor(0.0455)\n\n\n\n\n\n\n\n\n\nWith non linearly-separable data, the loss does not ever fully reach 0, once again performing similarly to the regular perceptron. Thus we see that when k = 1, minibatch perceptron performs similarly to regular perceptron.\n\n\nK = 10\n\nX, y = perceptron_data() \n\ntorch.manual_seed(12345) \np = Perceptron() \nopt = PerceptronOptimizer(p)\nloss = 1.0\nlossVecMinibatch = []\n\nn = X.size()[0]\n\nfor index in range(0, 1000):\n    loss = p.loss(X, y) \n    lossVecMinibatch.append(loss)\n    \n    k = 10\n    ix = torch.randperm(X.size(0))[:k]\n\n    xSubmatrix = X[ix]\n    ySubmatrix = y[ix]\n\n    # opt step with the random submatrix\n    opt.step(xSubmatrix, ySubmatrix)\n\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.figure(figsize=(10, 6))\n\nplt.plot(lossVecMinibatch, color = \"slategrey\")\nplt.scatter(torch.arange(len(lossVecMinibatch)), lossVecMinibatch, color = \"slategrey\", s=3)\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\nplt.title(f\"Evolution of the Loss Function with Multiple Dimensions\")\n#check final loss value as a means of verifying model \nfinalLossVal = lossVecMinibatch[len(lossVecMinibatch)-1]\nfinalLossVal\n\ntensor(0.)\n\n\n\n\n\n\n\n\n\nWhen k = 10, we can see that minibatch perceptron can still find a separating line in 2d, as its loss eventually reaches 0.\n\n\nK = n\n\nX, y = overlapPerceptronData() \n\ntorch.manual_seed(12345) \np = Perceptron() \nopt = PerceptronOptimizer(p)\nloss = 1.0\nlossVecMinibatch = []\n\nn = X.size()[0]\n\nfor index in range(0, 1000):\n\n    loss = p.loss(X, y)\n    lossVecMinibatch.append(loss)\n    \n    k = n\n    ix = torch.randperm(X.size(0))[:k]\n\n    xSubmatrix = X[ix]\n    ySubmatrix = y[ix]\n\n    # opt step with the random submatrix\n    opt.step(xSubmatrix, ySubmatrix)\n\n\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.figure(figsize=(10, 6))\n\nplt.plot(lossVecMinibatch, color = \"slategrey\")\nplt.scatter(torch.arange(len(lossVecMinibatch)), lossVecMinibatch, color = \"slategrey\", s=3)\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\nplt.title(f\"Evolution of the Loss Function with Multiple Dimensions\")\n#check final loss value as a means of verifying model \nfinalLossVal = lossVecMinibatch[len(lossVecMinibatch)-1]\nfinalLossVal\n\ntensor(0.0576)\n\n\n\n\n\n\n\n\n\nWhen k = n, meaning that the batch size the size of the entire data set, the minibatch perceptron can converge even when the data is not linearly separable, very nearly reaching a loss of 0.\n\n\nPart D: Writing\nWhat is the runtime complexity of a single iteration of the perceptron algorithm? Does the runtime complexity of a single iteration depend on the number of data points? What about the number of features? If you implemented minibatch perceptron, what is the runtime complexity of a single iteration of the minibatch perceptron algorithm?\nThe runtime complexity of a single iteration of the perceptron algorithm depends on the number of features (p). For each data point (represented by a row in feature matrix X), the perceptron algorithm computes the dot product the weight vector w and a row of the feature matrix X. Thus the runtime complexity of a single iteration is O(p).\nWith the minibatch perceptron, the runtime complexity of a single iteration is dependent on the size of the minibatch (k). The minibatch perceptron algorithm computes the dot product of each data point in the minibatch (rather than 1 single data point like in the typical perceptron algorithm). Thus the runtime complexity of a single iteration of the minibatch perceptron algorithm is O(kp).\n\n\nSummary Conclusion\nThrough this exploration of the Perceptron algorithm, I have learned its behavior in functionality and response to different types of data. Experimenting with different types of data revealed the perceptron’s ability to learn separating boundaries. Visualizations of evolution of the loss function allowed for easier understanding of how the algorithm itself operated, as well as revealing the differences between the behaviors of the perceptron algorithm on different types of data. I was ultimately able to successfully implement and use the perceptron algorithm for linearly separable data, non-linearly separable data, and data with more than 2 dimensions, as well as implement a version of the perceptron algorithm, the minibatch perceptron. This blog post serving as a guide to understanding the Perceptron Algorithm."
  },
  {
    "objectID": "posts/Regression/index.html",
    "href": "posts/Regression/index.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "In this blog post, I implement and experiment with gradient descent algorithms for logistic regression. I conducted three experiments, implementing Vanilla Gradient Descent, experiments to understand the benefits of momentum, and a final experiment to understand the dangers and harms of overfitting the logistic regression model on training data. I was able to make several meaningful conclusions. Implementing Vanilla Gradient Descent where beta =0 led to convergence with monotonically decreasing loss, however with benefits of momentum, such as where beta = 0.9, loss decreased at a faster rate, converging with fewer iterations than needed for Vanilla Gradient Descent. The experiment in which I fit the model too closely to the training data showed lower accuracy on the test data, warning against overfitting. I was able to learn more about logistic regression as a machine learning model throughout the implementation and exploration of this blog post."
  },
  {
    "objectID": "posts/Regression/index.html#vanilla-gradient-descent",
    "href": "posts/Regression/index.html#vanilla-gradient-descent",
    "title": "Logistic Regression",
    "section": "Vanilla Gradient Descent",
    "text": "Vanilla Gradient Descent\nThe first experiment I performed was vanilla gradient descent. When there are 2 dimensions, alpha is sufficently small, and beta is 0, I expect to see gradient descent for logistic regression converge to a weight vector w, the loss decreasing monotonically (either only increasing or only decreasing).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nlossVec = [] \n\nfor _ in range(4000):\n    # VGD alpha small and beta 0 \n    opt.step(X, y, alphaRate = 0.4, betaRate = 0)\n    loss = LR.loss(X,y)\n    lossVec.append(loss)\n\n\n#then plot loss over iterations, v similar to how we did in the perceptron blog post \ndef plotLoss(loss, label =\"\"):\n    plt.style.use('seaborn-v0_8-whitegrid')\n    plt.figure(figsize=(10, 6))\n\n    \n    plt.plot(lossVec, color = \"blue\", label = label)\n    plt.scatter(torch.arange(len(loss)), loss, color = \"blue\", s=3)\n    plt.gca().set(xlabel = \"Iterations\", ylabel = \"loss\")\n    \n    plt.title(f\"Evolution of the Loss Function\")\n    #check final loss value as a means of verifying model \n    finalLossVal = loss[len(loss)-1]\n\nplotLoss(lossVec)\n\n\n\n\n\n\n\n\nFrom the plot, we can see that the loss is decreasing the entire time (and thus loss decreasing monotonically!), in line with our expected behavior of vanilla gradient descent. We can further visualize the result of the model by plotting the data with its new decision boundary.\n\ndef drawLine(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    l = ax.plot(x, y, **kwargs)\n\ndef plotData (X, y, ax):\n    #from perceptron blog post, but targets now 0,1 for binary classification\n    targets = [0, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n    \nfig, ax = plt.subplots(1, 1)\nplotData(X, y, ax)\ndrawLine(LR.w, x_min=-1, x_max=2, ax=ax, color=\"black\")\n#checking the final loss to verify model\nax.set_title(f\"loss = {loss:.3f}\")\n\nText(0.5, 1.0, 'loss = 0.196')\n\n\n\n\n\n\n\n\n\nThe model did a good job of finding a separating line between the two distinct classes, with the final loss being around 0.1.\n\nBenefits of Momentum\nThe next experiment I performed was to show the benefits of momentum. On the same data, we expect to see gradient descent with momentum (when beta is a non-zero value such as 0.9) is able to converge to the correct weight vector faster, in fewer iterations than the previous experiment of vanilla gradient descent (where beta = 0).\n\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\nX, y = classification_data(noise = 0.2)\n\nlossVecMomentum = []\n\nfor index in range(4000):\n    # alpha small and beta nonzero = 0.9\n    opt.step(X, y, alphaRate = 0.4, betaRate = 0.9)\n    loss = LR.loss(X, y)      \n    lossVecMomentum.append(loss)\n\n\n#first plot loss function with benefits of momentum \nplotLoss(lossVecMomentum, label = \"BoM, beta = 0.9\")\n\n#add on plot of VGD\nplt.plot(lossVec, color = \"slategrey\", label = \"VDG, beta = 0\")\nplt.scatter(torch.arange(len(lossVec)), lossVec, color = \"slategrey\", s=3)\nplt.gca().set(xlabel = \"Iterations\", ylabel = \"Loss\")\nplt.legend()\n\n\n\n\n\n\n\n\nWe can see that the loss function of gradient descent with benefits of momentum (represented in blue), is decreasing faster, converging to the correct weight vector in fewer iterations than the previous experiment of vanilla gradient descent. This shows that larger non-zero beta values does allow the model to learn at a quicker rate.\n\n\nThe Dangers of Overfitting\nThe last experiment I performed is to show how overfitting can be harmful, looking at its effects. I can do so by creating na instance where I obtain 100% testing accuracy, looking at data where the number of dimensions is greater than the number of points.\nWe first implement the model on the training set, checking to see if our goal of 100% accuracy has been reached.\n\n#first the training set\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\nX_train, y_train = classification_data(n_points = 50, noise = 0.5, p_dims = 100)\n\nlossVecTrain = []\nfor index in range(4000):\n    #do i need to lower alpha?\n    opt.step(X_train, y_train, alphaRate = 0.4, betaRate = 0.9)\n    loss = LR.loss(X_train, y_train) \n    lossVecTrain.append(loss)\n\ndef accuracy(X, y):\n    predictions = LR.predict(X)\n    predsCorrect = (predictions == y).float()\n    acc = torch.mean(predsCorrect)\n    return acc\n\nWe can see that we have indeed achieved accuracy on the training data. Let’s repeat the process but now on the testing data, and look at the accuracy once more.\n\nfinalTrainAcc = accuracy(X_train, y_train)\nprint(\"Final Training Accuracy:\", finalTrainAcc.item())\n\n\n#then the testing set\nX_test, y_test = classification_data(n_points = 50, noise = 0.5, p_dims = 100)\nfinalTestAcc = accuracy(X_test, y_test)\nprint(\"Final Testing Accuracy:\", finalTestAcc.item())\n\nFinal Training Accuracy: 1.0\nFinal Testing Accuracy: 0.9599999785423279\n\n\nThe results show that the model has been overfit to the training data. Despite having 100% accuracy on the training data, the model cannot reach the same level of accuracy on the testing data, only reaching about 96% as opposed to 100%. This overfitted model would not perform as well as unseen data, due to its overfitting.\n\n\nConclusion\nOverall in this blog post, through the implementation and experimentation of a fundamental algorithm of machine learning, the logistic regression model. Through three experiements: Vanilla Gradient Descent, Benefits of Momentum, and the Dangers of Overfitting, I was able to gain insights and a deeper understanding of the behavior and performance of logistic regression models as they pertain to gradient descent, observing the effects of various changes and conditions. Visualizations served as a helpful tool in order to understand and validate the models behavior. With Vanilla Gradient Descent where beta =0 we can see that convergence does indeed occur after a certain amount of iterations. Experimenting with momentum showed the benefits of higher beta values (such as beta = 0.9), in order to increase momentum, allowing for faster convergence, outperforming the first experiment of vanilla gradient descent. Fitting the model too closely to the training data showed lower accuracy on the test data, warning against overfitting. This blog post provided me a comprehensive overview and understanding of gradient descent algorithms for logistic regression, through implementation, experimentation, and visualization."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "CSCI 0451: Mid-Course Reflection\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCSCI 0451: Reflective Goal-Setting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogistic Regression\n\n\n\n\n\nBlog Post 5: Implementing Logistic Regression\n\n\n\n\n\nApr 12, 2024\n\n\nJulia Joy\n\n\n\n\n\n\n\n\n\n\n\n\nOptimal Decision Making\n\n\n\n\n\nBlog Post 5\n\n\n\n\n\nMar 31, 2024\n\n\nJulia Joy\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing the Perceptron Algorithm\n\n\n\n\n\nBlog Post 4: Implementing and testing the perceptron algorithm.\n\n\n\n\n\nMar 31, 2024\n\n\nJulia Joy\n\n\n\n\n\n\n\n\n\n\n\n\nWiDS Conference at Middlebury College\n\n\n\n\n\nBlog Post 3: Refelcting on and contextualizing the learning obtained from the Women in Data Science Conference\n\n\n\n\n\nMar 4, 2024\n\n\nJulia Joy\n\n\n\n\n\n\n\n\n\n\n\n\nDissecting Racial Bias\n\n\n\n\n\nBlog Post 2: Dissecting racial bias in an algorithm used to manage the health of populations\n\n\n\n\n\nFeb 29, 2024\n\n\nJulia Joy\n\n\n\n\n\n\n\n\n\n\n\n\nPalmer Penguins\n\n\n\n\n\nBlog Post 1: Palmer Penguins\n\n\n\n\n\nFeb 18, 2024\n\n\nJulia Joy\n\n\n\n\n\n\nNo matching items"
  }
]