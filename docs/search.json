[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi! My name is Julia Joy."
  },
  {
    "objectID": "posts/GoalSetting/index.html",
    "href": "posts/GoalSetting/index.html",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "Julia Joy\n\n\nThe knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nI think that the areas that i would most like to focus on are primarily the Implementation. I always feel like more practice with effective coding and learning how to use new tools is so invaluable, I am excited to continue that in this course, especially with all the different kinds of Machine Learning algorithms and models. I am also interested in the Theory aspect as a mathematics minor, I love learning about the numbers and formulas that go behind the operations we can take for granted when we code. I never took multi-calculus (I know, odd for a math minor), so while I think it will be a bit challenging to dredge up my calc and linear algebra since I took those courses so long ago, I think it will be rewarding and fun to expand my knowledge.\n\n\n\n\n\nMost blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\nI think blog posts will be pretty crucial to my learning in this course. Already with the first blog post and working on the second, I enjoy taking the content we discuss in class and applying it on my own. I have always felt like a hands-on learning style fits me the best. Ideally I would like to have a “Satisfactory/No Revision Required” rating on 5-6 of my of my blog posts, and perhaps completing more (I want to complete at least around 60-80% of blog posts) but leaving some space for some blog posts to remain in the “needs revision category”. I have realized that I am someone who is very driven by interest when it comes to coursework. Assignments I enjoy are fun little challenges for me, and I will spend hours working and tweaking them to my satisfiability even when they’re already probably pass the threshold of “good enough” grade wise. But assignments with content that I am not as passionate or interested about can be really hard for me to motivate to spend extra time on, so I would enjoy leaving some space for myself to say “no I think that is good enough for me. I tried it out and am satisfied with my work.”. I aim to give myself about 1-1.5 weeks for a fresh first-draft submission of each blog post I do, just to keep myself on a semi-timeline to ensure nothing gets crammed in at the end. With revision, I think that will be more dependent on extra time I have each week, spending more time on it in the weeks I have a bit more extra time and vice versa, I will allow myself less of a set timeline with those.\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\nI strive to attend every class, with the exception of one to two when it is truly necessary to miss class, such as if I’m sick, have to be out of town for some reason, or if my mental health gets in the way of my academics. In our two weeks of class, I have already gained an appreciation for the daily warmups. I find myself actually spending a good chunk of time on them before class, but I feel like it really does benefit me. The warmups prep me and lay a groundwork for either just basic understanding for the subject we tackle in that class, or in the application of what we’re about to talk about. I aim to complete every warmup prior to class this semester, with the leeway of one or two because life does happen. Outside of completing each warmup, whenever we are in our small groups, I aim to be very involved and ask questions and offer suggestions/solutions to whoever is the warmup presenter. I hope to complete most of the course readings, using it as more of a supplement to my hands on learning. Additionally, I notice that I frequently find it challenging to speak up in class, especially in a large class full of many people who are not only my peers but also my friends. The warmups in small groups help ease the transition before I potentially have to speak in front of the whole class. While I do still find it a bit intimidating, I really appreciate and value being able to talk the problems out in a smaller group setting before a larger one. Peer help/TA/office hours have long time been my favorite way to address questions or concepts I have a hard time grasping, so I expect to attend those when the need strikes. I have realized I am much more of a ask-questions-in-person kind of person than a slack questions user, so while I will check the slack and at some point probably use it to send a chat myself, I do not expect frequent use of it for myself. I think study groups will be big for me this semester, as I am familiar with many people in this course, so I think that will also be beneficial in my learning if I get stuck anywhere and help hours are immediately around.\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\nI am excited about this project as I feel like it will allow me to explore what machine learning can be in an area that I’m a bit more interested in, whatever that may be. Without knowing exactly what my project will look like or be about I cannot detail my goals in that way, however I know some general ideas of what I would like to accomplish. I would like to complete all project milestones on time to keep myself and the group accountable in our semester time frame, contribute to the project in an equal manner including in the algorithm implementation and project presentation, and do what I can to be a great group project partner. I think that everyone has strengths and weaknesses, and for example while I don’t think that I’m the best at writing automated checks for algorithms written by others, I have other skills to offer. I think that is the most important thing about working in a team, to acknowledge everyone’s weaknesses and capitalize on peoples strengths."
  },
  {
    "objectID": "posts/GoalSetting/index.html#what-youll-learn",
    "href": "posts/GoalSetting/index.html#what-youll-learn",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "The knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nI think that the areas that i would most like to focus on are primarily the Implementation. I always feel like more practice with effective coding and learning how to use new tools is so invaluable, I am excited to continue that in this course, especially with all the different kinds of Machine Learning algorithms and models. I am also interested in the Theory aspect as a mathematics minor, I love learning about the numbers and formulas that go behind the operations we can take for granted when we code. I never took multi-calculus (I know, odd for a math minor), so while I think it will be a bit challenging to dredge up my calc and linear algebra since I took those courses so long ago, I think it will be rewarding and fun to expand my knowledge."
  },
  {
    "objectID": "posts/GoalSetting/index.html#what-youll-achieve",
    "href": "posts/GoalSetting/index.html#what-youll-achieve",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "Most blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\nI think blog posts will be pretty crucial to my learning in this course. Already with the first blog post and working on the second, I enjoy taking the content we discuss in class and applying it on my own. I have always felt like a hands-on learning style fits me the best. Ideally I would like to have a “Satisfactory/No Revision Required” rating on 5-6 of my of my blog posts, and perhaps completing more (I want to complete at least around 60-80% of blog posts) but leaving some space for some blog posts to remain in the “needs revision category”. I have realized that I am someone who is very driven by interest when it comes to coursework. Assignments I enjoy are fun little challenges for me, and I will spend hours working and tweaking them to my satisfiability even when they’re already probably pass the threshold of “good enough” grade wise. But assignments with content that I am not as passionate or interested about can be really hard for me to motivate to spend extra time on, so I would enjoy leaving some space for myself to say “no I think that is good enough for me. I tried it out and am satisfied with my work.”. I aim to give myself about 1-1.5 weeks for a fresh first-draft submission of each blog post I do, just to keep myself on a semi-timeline to ensure nothing gets crammed in at the end. With revision, I think that will be more dependent on extra time I have each week, spending more time on it in the weeks I have a bit more extra time and vice versa, I will allow myself less of a set timeline with those.\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\nI strive to attend every class, with the exception of one to two when it is truly necessary to miss class, such as if I’m sick, have to be out of town for some reason, or if my mental health gets in the way of my academics. In our two weeks of class, I have already gained an appreciation for the daily warmups. I find myself actually spending a good chunk of time on them before class, but I feel like it really does benefit me. The warmups prep me and lay a groundwork for either just basic understanding for the subject we tackle in that class, or in the application of what we’re about to talk about. I aim to complete every warmup prior to class this semester, with the leeway of one or two because life does happen. Outside of completing each warmup, whenever we are in our small groups, I aim to be very involved and ask questions and offer suggestions/solutions to whoever is the warmup presenter. I hope to complete most of the course readings, using it as more of a supplement to my hands on learning. Additionally, I notice that I frequently find it challenging to speak up in class, especially in a large class full of many people who are not only my peers but also my friends. The warmups in small groups help ease the transition before I potentially have to speak in front of the whole class. While I do still find it a bit intimidating, I really appreciate and value being able to talk the problems out in a smaller group setting before a larger one. Peer help/TA/office hours have long time been my favorite way to address questions or concepts I have a hard time grasping, so I expect to attend those when the need strikes. I have realized I am much more of a ask-questions-in-person kind of person than a slack questions user, so while I will check the slack and at some point probably use it to send a chat myself, I do not expect frequent use of it for myself. I think study groups will be big for me this semester, as I am familiar with many people in this course, so I think that will also be beneficial in my learning if I get stuck anywhere and help hours are immediately around.\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\nI am excited about this project as I feel like it will allow me to explore what machine learning can be in an area that I’m a bit more interested in, whatever that may be. Without knowing exactly what my project will look like or be about I cannot detail my goals in that way, however I know some general ideas of what I would like to accomplish. I would like to complete all project milestones on time to keep myself and the group accountable in our semester time frame, contribute to the project in an equal manner including in the algorithm implementation and project presentation, and do what I can to be a great group project partner. I think that everyone has strengths and weaknesses, and for example while I don’t think that I’m the best at writing automated checks for algorithms written by others, I have other skills to offer. I think that is the most important thing about working in a team, to acknowledge everyone’s weaknesses and capitalize on peoples strengths."
  },
  {
    "objectID": "posts/DecisionMaking/index.html",
    "href": "posts/DecisionMaking/index.html",
    "title": "Dissecting Racial Bias",
    "section": "",
    "text": "Abstract\nThis exploratory analysis aims to replicate the primary findings of Obermeyer et al. in their study of ‘Dissecting racial bias in an algorithm used to manage the health of populations’ (2019). By reproducing various figures, such as Mean Number of Chronic Illnesses by Percentile Risk Score and Total Medical Expenditure vs. Number of Chronic Illnesses, as well as fitting a linear regression model, this analysis aims to determine if there exists substansial disparity between the risk score and medical costs incurred of black and white patients. The findings indicate that there does indeed exists a disparity between both the attributed risk score and the medical costs incurred of the patients by race. The risk score of white patients are higher than their black patient counterparts who have the same number of chronic illnesses. The costs follow a similar pattern, where white patients incur greater medical costs than their black patient counterparts who have the same number of chronic illnesses. Black patients incur approximately 75% of the costs that white patients incur. These finding suggest that black patients are not getting the health care they need, as they are deprioritized with lower risk scores and receiving less needed healthcare as they take on less medical costs.\n\n\nPART A: Data Access\nLoading in the data, I take a preliminary view to understand the meaning of the respective rows and columns.\n\n# load data \nimport pandas as pd\nurl = \"https://gitlab.com/labsysmed/dissecting-bias/-/raw/master/data/data_new.csv?inline=false\"\ndf = pd.read_csv(url)\n\n\ndf.head()\n\n\n\n\n\n\n\n\nrisk_score_t\nprogram_enrolled_t\ncost_t\ncost_avoidable_t\nbps_mean_t\nghba1c_mean_t\nhct_mean_t\ncre_mean_t\nldl_mean_t\nrace\n...\ntrig_min-high_tm1\ntrig_min-normal_tm1\ntrig_mean-low_tm1\ntrig_mean-high_tm1\ntrig_mean-normal_tm1\ntrig_max-low_tm1\ntrig_max-high_tm1\ntrig_max-normal_tm1\ngagne_sum_tm1\ngagne_sum_t\n\n\n\n\n0\n1.987430\n0\n1200.0\n0.0\nNaN\n5.4\nNaN\n1.110000\n194.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n7.677934\n0\n2600.0\n0.0\n119.0\n5.5\n40.4\n0.860000\n93.0\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n4\n3\n\n\n2\n0.407678\n0\n500.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0.798369\n0\n1300.0\n0.0\n117.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n17.513165\n0\n1100.0\n0.0\n116.0\nNaN\n34.1\n1.303333\n53.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n\n\n\n\n5 rows × 160 columns\n\n\n\n\n\nPART B: Reproducing Figure 1\n\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n\nblackDF= df[df[\"race\"] == \"black\"].copy()\nblackDF['risk_percentile'] = (df['risk_score_t'].rank(pct=True) * 100).round()\nmeanCCblack = blackDF.groupby('risk_percentile')['gagne_sum_t'].transform('mean')\nblackDF['meanCCblack'] = meanCCblack\n\n \nwhiteDF = df[df[\"race\"] == \"white\"].copy()\nwhiteDF['risk_percentile'] = (df['risk_score_t'].rank(pct=True) * 100).round()\nmeanCCwhite = whiteDF.groupby('risk_percentile')['gagne_sum_t'].transform('mean')\nwhiteDF['meanCCwhite'] = meanCCwhite\n\n\n\nsns.scatterplot(x='meanCCblack', y='risk_percentile', data=blackDF, color='teal', label='Black')\nsns.scatterplot(x='meanCCwhite', y='risk_percentile', data=whiteDF, color='orange', label='White')\n\nplt.xlabel('Mean Number of Chronic Illnesses by Percentile Risk Score')\nplt.ylabel('Percentile Risk Score')\nplt.title('Mean Number of Chronic Illnesses')\nplt.legend(title='Race')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nAs we see from the plot, Patient A and Patient B are not equally likely to be referred to the high-risk care management program. Given the same number of active chronic conditions, white patients tend to score higher risk scores compared to their black counterparts. Thus white patients, such as patient A would be more likely to be referred to the high-risk care management program than black patients such as patient B. As Obermeyer et al said, “less-healthy Blacks scored at similar risk scores to more-healthy Whites” and thus there is evidence for “substantial disparities” in the program.\n\n\nPART C: Reproducing Figure 3\n\ndf['risk_percentile'] = (df['risk_score_t'].rank(pct=True) * 100).round()\nriskCostDF = df.groupby(['risk_percentile','race']).aggregate(['cost_t'].mean()).reset_index()\n\n\n\nsns.scatterplot(x='risk_percentile', y='cost_t', hue = 'race', data=riskCostDF)\nplt.xlabel('Percentile Risk Score')\nplt.ylabel('Total Medical Expenditure')\nplt.title('Total Medical Expenditure vs. Percentile Risk Score')\nplt.grid(True)\nplt.yscale('log')\nplt.show()\n\nAttributeError: 'list' object has no attribute 'mean'\n\n\n\nblackDF = df[df[\"race\"] == \"black\"].copy()\nwhiteDF = df[df[\"race\"] == \"white\"].copy()\n\nchronicCostBlack = blackDF.groupby('gagne_sum_t')['cost_t'].mean().reset_index()\nchronicCostWhite = whiteDF.groupby('gagne_sum_t')['cost_t'].mean().reset_index()\n\nsns.scatterplot(x='gagne_sum_t', y='cost_t', data=chronicCostBlack, label =\"White\")\nsns.scatterplot(x='gagne_sum_t', y='cost_t', data=chronicCostWhite, label =\"Black\")\nplt.xlabel('Number of Chronic Illnesses')\nplt.ylabel('Total Medical Expenditure')\nplt.title('Total Medical Expenditure vs. Number of Chronic Illnesses')\nplt.legend(title='Race')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFrom the reproduction of these two figures, we can better understand our data. We note that a vast majority of patients in this data set have 5 or fewer chronic conditions. A surprising finding that there exists more disparity in health conditional risk than in costs. However, black patients have lower costs on average than their white patient counterparts, potentially suggesting they are not getting the care they need. To accurately predict costs for patients, their race is crucial information as it distinguishes their predicted costs, this suggests that the relationship between the number of chronic conditions and the cost might be nonlinear.\n\n\nPART D: Modeling Cost Disparity\n\nCostDisparityDF = df[df['gagne_sum_t'] &lt;= 5]\nfiveChronics = CostDisparityDF.shape[0]\ntotalPatientsNum = df.shape[0]\npercentFiveChronics = (fiveChronics / totalPatientsNum) * 100\n\nAbout 95 percent of patients have five or less chronic conditions. Since this is the vast majority of patients, it is justified to focus in on these patients\n\nCostDisparityDF = CostDisparityDF[CostDisparityDF['cost_t'] &gt; 0]\nCostDisparityDF['logCost'] = np.log(CostDisparityDF['cost_t'])\n\nCostDisparityDF['OneHotRace'] = (CostDisparityDF['race'] == 'black').astype(int)\n\n#separate into predictor variables and target variable \npredictorX = CostDisparityDF[['OneHotRace', 'gagne_sum_t']]\ntargetY = CostDisparityDF['logCost']\n\n\n\ntargetY\n\n0        7.090077\n1        7.863267\n2        6.214608\n3        7.170120\n4        7.003065\n           ...   \n48779    6.684612\n48780    7.696213\n48781    6.684612\n48782    7.170120\n48783    8.389360\nName: logCost, Length: 44748, dtype: float64\n\n\nAs indicated in the findings from my figures above, the relationship between the number of chronic conditions and the cost might be nonlinear. Thus in order to fit a linear regression model, we must fit the model with a certain number of polynomial features of active chronic condition in order to to account for the nonlinearity. To determine how many polynomial features should be used for best predictions on this data set, cross validation is needed to test various data sets with differing number of polynomial feature sizes. For each possible polynomial feature size, a LinearRegression model is constructed a cross validation score is computed.\n\ndef add_polynomial_features(X, degree):\n  X_ = X.copy()\n  for j in range(1, degree):\n    X_[f\"poly_{j}\"] = X_[\"gagne_sum_t\"]**j\n  return X_\n\n\nfrom sklearn.linear_model import LinearRegression as LR\nfrom sklearn.model_selection import cross_val_score\n#test each num of active chronic conditions \ncvScores = []\n\nfor degree in range (1,6):\n    X_poly = add_polynomial_features(predictorX, degree)\n    modelToEvaluate = LR()\n    scores = cross_val_score(modelToEvaluate, X_poly, targetY, cv=5, scoring='explained_variance')\n    cvScores.append(np.mean(scores))\n\n    modelToEvaluate.fit(X_poly, targetY)\n\n\ncvScores\n\n[0.08547350567418092,\n 0.0854752316405665,\n 0.0862993008389995,\n 0.08704835621632338,\n 0.08740844467965052]\n\n\n\n#fit the one that is best \npredictorX = add_polynomial_features(predictorX,6)\nfinalModel = LR()\nfinalModel.fit(predictorX, targetY)\nfinalModel.coef_\n\narray([-0.2827181 ,  0.5939195 ,  0.5939195 , -1.28588299,  0.65937337,\n       -0.14306628,  0.01107307])\n\n\nOnce the size of the polynomial feature that is most resonable for this dataset is determined, I fit one last linear regression model with the correct number of polynomial features, which in this case, is all 5.\n\ncostIncurred = np.exp(finalModel.coef_[0])\ncostIncurred\n#0.75\n\n0.7537322331638742\n\n\nFinally, e^W(b) is computed, which represents the cost incurred by black patients as a percentage of white patients. We find this number to be 0.75, which means that black patients incur 75% of the cost that white patients incur. This finding does indeed roughly support the argument of Obermeyer et al. (2019), as Obermeyer et al. claimed that there were opportunites for a disparity wedge to occur between needing health care and receiving health care, claiming that this disparity wedge was found to be correlated with race. Our findings indicate the same thing, since the interpretation of our 75% cost incurred figure could mean that a black patient with the same amount of chronic illnesses as a white patient would be paying less (and thus assumed to be receiving less needed healthcare).\n\n\nPart E: Discussion\nThroughout this exploratory analysis that aimed to replicate the primary findings of Obermeyer et al. in their study of ‘Dissecting racial bias in an algorithm used to manage the health of populations’ (2019), we find similar results and conclusions. By contructing plot figures and linear regression models, I learned that there does indeed exists a disparity between both the attributed risk score and the medical costs incurred of the patients by race. The risk score of white patients are higher than their black patient counterparts who have the same number of chronic illnesses. The costs follow a similar pattern, bBlack patients incurring approximately 75% of the costs that white patients incur, where both sets of patient counterparts have the same number of chronic illnesses. These finding suggest that black patients are not getting the health care they need, as they are deprioritized with lower risk scores and receiving less needed healthcare as they take on less medical costs. The importance of constructing a linear regression model with the proper number of polynomial features was emphasized in this analysis. Additionally, I gained an appreciation for extrapolating findings beyond their face value. Black patients incur less medical costs than their white counterparts with the same number of chronic illnesses. Why? Perhaps because they are not receiving the full extent of the healthcare they need and are thus paying less medical costs.\nWhat aspects of the study support your answer?\nOf the three statistical discrimation criteria discussed in Chapter 3 of Barocas, Hardt, and Narayanan (2023)- error rate parity, acceptance rate parity/independence, and sufficiency (calibration), the criteria that best describes the purported bias of the algorithm studied by Obermeyer et al. (2019) is error rate parity. I believe that error rate parity best describes the purported bias of the algorithm because the algorithm systematically assigns lower risk scores to black patients compared to white patients with the same number of chronic illnesses which can/does lead to unequal treatment and resource allocation in healthcare. The aspects of the study that support my answer is Obermeyer et al.’s commentary that this bias is “attributable to label choice—the difference between some unobserved optimal prediction and the prediction of an algorithm trained on an observed label”. They claim that labels can be often measured in an error-prone way that reflect structural inequalities. This model has a problem with error rate parity as it does not make errors at similar rates for different groups to ensure fairness."
  },
  {
    "objectID": "posts/Palmer Penguins/index.html",
    "href": "posts/Palmer Penguins/index.html",
    "title": "Palmer Penguins",
    "section": "",
    "text": "The aim of this exploration of the Palmer Penguins dataset is to gain insight into the dataset through predictive classification. This exploration involves constructing visualizations of the data using seaborn and creating informative summary tables using pandas. By testing various combinations of models through a reproducible process, three key features are able to be identified. Out of the three features, I found that the combination of 1 qualitative feature: Clutch Completion, and 2 quantitative features: Culmen Length and Culmen Depth, were the most effective to reach 100% testing classification accuracy using a Decision Tree Model. The evaluation phase provides a visual representation of the models behavior by showing the decision regions of the trained decision tree model. Through this process, we gain a comprehensive understanding of the Palmer Penguins dataset and demonstrate the effectiveness of a trained decision tree model in accurately classifying Palmer Penguin data.\nimport pandas as pd\ntrain_url = “https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv” train = pd.read_csv(train_url)\nWe can take a peek at the data to get a better idea of where to start, by using .head()\ntrain.head()"
  },
  {
    "objectID": "posts/Palmer Penguins/index.html#figure-findings",
    "href": "posts/Palmer Penguins/index.html#figure-findings",
    "title": "Palmer Penguins",
    "section": "Figure Findings",
    "text": "Figure Findings\nVarious summary tables and visualizations were tested, aiming to determine the most effective presentation of the Palmer Penguins dataset. Initially different grouping criteria and variables were considered, such as species, island, sex, clutch completion, culmen depth and length, body mass, and flipper length. Ultimately I decided to come back and choose the summary table and visualizations that reflected the variables I later found to have the highest predictive accuracy: Culmen Depth, Culmen Length, and Clutch Completion. Summary tables were created using pandas.groupby().aggregate. From the summary tables we observe that among different species, Culmen Length varies to a larger degree than Culmen Depth does. Upon a glance of the summary table, it is hard to see if clutch completion and culmen characteristics are correlated. In the first visualization on the right, we can see the penguins depicted by virtue of the respective culmen length and depth, colored by the Clutch Completion. We observe a relatively uniform distribution of clutch completion- there does not seem to be an immediate observable relationship between the three. My next visualization shows the same axes of Culmen Depth and Length, this time however colored by species. In this figure, we notice clear species groupings, corresponding to their Culmen Depth-Length relationship."
  },
  {
    "objectID": "posts/Palmer Penguins/index.html#find-the-best-features-for-prediction",
    "href": "posts/Palmer Penguins/index.html#find-the-best-features-for-prediction",
    "title": "Palmer Penguins",
    "section": "Find the Best Features for Prediction",
    "text": "Find the Best Features for Prediction\nIn order to ensure our model has the highest classification accuracy possible, we need to select features that are more indicative of the species group a penguin belongs to. By testing every combination of features, we are able to find the three that result in the highest training set accuracy. We find that there are multiple 3-feature sets with 100% training set classification accuracy.\n\nfrom itertools import combinations\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n# these are not actually all the columns: you'll \n# need to add any of the other ones you want to search for\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island\"]\nall_quant_cols = ['Flipper Length (mm)','Culmen Length (mm)', 'Culmen Depth (mm)']\n\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = qual_cols + list(pair) \n    print(cols)\n    # you could train models and score them here, keeping the list of \n    # columns for the model that has the best score. \n    #DT = DecisionTreeClassifier()\n    #DT.fit(X_train[cols], y_train)\n    #print(DT.score(X_train[cols], y_train))\n\nIn order to narrow these feature-sets down to the single set that will be the most effective and give us not only 100% training set classificaiton accuracy but also 100% testing set classification accuracy, we repeat the process from earlier. Now operating on the testing set, we narrow down the 3-feature sets into one final best feature set: Clutch Completion, Culmen Length (mm), and Culmen Depth (mm).\n\n#pretend we're numbering these from 1-9, look at testing accuracy for each one that has 1.0. \n\ntempCols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']\nDT = DecisionTreeClassifier()\nDT.fit(X_train[tempCols], y_train)\nprint(DT.score(X_train[tempCols], y_train))\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\nDT.score(X_test[tempCols], y_test)\n\n\n#1 0.97\n#2 nope\n#3 1.0 !!!  ['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n#4 0.97\n#5 nope\n#6 0.98\n#7 0.98\n#nope\n#9 0.98\n\nWe check our cross-validation score, noting that a cross validation score of 94.5% is indicitive of future model generalizability.\n\n#cross-validation\nfrom sklearn.model_selection import cross_val_score\ncv_scores_DT = cross_val_score(DT, X_train, y_train, cv=5)\ncv_scores_DT.mean()\n\n\nPlotting Decision Regions\nFinally, we can visualize these Decision Regions using matplotlib.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\n\n#visualizing decision regions on train set \nplot_regions(DT, X_train[keepCols], y_train)\n\n\n#visualizing decision regions on test set\nplot_regions(DT, X_test[keepCols], y_test)\n\n\n\nConfusion Matrix\n\n#need to truncate X_test to have only the columns we're using to predict before doing confusion matrix\nX_test = X_test[['Culmen Length (mm)', 'Culmen Depth (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']]\n\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = DT.predict(X_test)\ny_test_pred\n\nC = confusion_matrix(y_test, y_test_pred)\nC\n\nSince the trained model has 100% training and testing classifcation accuracy, the confusion matrix reflects the lack of classification errors.\n\n\nSummary Discussion\nIn conclusion, this exploration of the Palmer Penguins dataset has provided insights into the dataset through predictive classification. Through the construction of informative summary tables and visually appealing figures, we were able to uncover various patterns, trends, and relationships within the data. By systematically testing different combinations of both qualitative and quantitative features of the Palmer Penguins, I found the best combination of three features that yielded high classification accuracy. One qualitative feature, clutch completion, and two quantitative features, culmen length and culmen depth (mm). By employing scikit-learn’s DecisionTreeClassifier, I trained a model on these features and achieved a classification accuracy of 100% on both the training and testing sets. This shows the importance of feature selection, model selection and evaluation in building accurate predictive models. Through this whole process, I gained a comprehensive understanding of the Palmer Penguins dataset and demonstrate the effectiveness of a trained model in accurately classifying Palmer Penguin data. From this process, I learned how important both the selection of the right features as well as the right model are. I learned that 100% training set classification accuracy does not guarantee 100% testing set classification accuracy, and how it is important to tweak the model to ensure that future uses beyond a training set maintain a high level of accuracy. I gained an appreciation of visualizations as a tool for greater understanding of initial data as well as the effect of models. I feel confident in future endeavors to explore, visualize, and predict data."
  },
  {
    "objectID": "posts/WIDS Conference/index.html",
    "href": "posts/WIDS Conference/index.html",
    "title": "WiDS Conference at Middlebury College",
    "section": "",
    "text": "Abstract:\n\n\nPart 1: Why Spotlight Women in Data Science?\n\n\nWhy is it a problem that women are underrepresented in computing, math, and engineering? For whom is it a problem?\nGender biases can create obstacles not only for women in technical workplaces but also for the men who work with them. In one study of equally performing teams working on a male-typed task, teams with a higher percentage of women rated both their female and male peers’ work more negatively overall and expressed less desire to work together in the future (West et al., 2012). Another study found that in a typically male field, people rated their male colleagues as less masculine and less deserving of workplace success if they had female supervisors (Brescoll, Uhlmann et al., 2012). This research sheds light on the magnitude of the problem of gender bias in predominantly male fields and perhaps points to one mechanism by which it is maintained. If men’s work is devalued when men work with women, men might take steps to avoid working with women, exacerbating the challenges facing women in male-dominated fields. While diversity has demonstrated benefits, there are real challenges to achieving it.\nDiversity in the workforce contributes to creativity, productivity, and innovation. Women’s experiences—along with men’s experiences—should inform and guide the direction of engineering and technical innovation The United States simply can’t afford to ignore the perspectives of half the population in future engineering and technical designs. lose out on these high-quality job opportunities that account for more than 80% of stem workforce more likely to choose a male candidate over an identical female candidate for a hypothetical job opening at a lab. Both female and male scientists also offered a higher salary to the male candidate. Gender biases affect not only how we view and treat others but also how we view ourselves and what actions we take as a result\n\n\nWhich of the barriers and unequal challenges described in the section “Why So Few?” can be eroded by events that spotlight the achievement of women in STEM?\nThe section “Why so Few?” outlines various barriers and unequal challenges women face in the STEM field, such as sense of belonging, stereotypes and stereotype threat, challenging academic workspaces, as well as isolation. Women may face negative impacts such as experiencing difficultly balancing expected gendered home responsibilities and the culture of overwork, feel deincentivized by the engineering culture of disengagement as studies show women are more likely than men to express a preference for work with a clear social purpose (Konrad et al., 2000), or feel isolated as significant portion of women reported feeling as if they lacked role models and mentors and did not agree with the statement that “it is safe to speak up most of the time”. While not all of these barriers or challenges can be eroded by events that spotlight the achievement of women in STEM, there are a few that can benefit from these events.\nWhat stood out most notably to me that could be benefited by these events was improving the sense of belonging for women in STEM. Events that spotlight the achievement of women in STEM shows examples of women in a historically male-dominated field, helping combat both internalized and external stereotypes. These events show women that success in STEM is possible, providing role models and mentors, increasing womens sense of belonging and thus hopefully increasing the number of women in STEM.\nBIAS AND STEOROTYPES isolation lacking role models, lacking mentors, Many women report lacking role models and role models (about half reported lacking mentors in a study done by Hewlett et al., 2008).\nIn the STEM field, women face gender stereotypes…, that all contribute to a lower sense of belonging than men in the same field.\n\nPart 2: Attending the Women in Data Science Conference. Yay!\n\n\nPart 3: Report\nFor each of the three lightning talks, please write a paragraph describing who spoke, what they spoke about, their main argument, and what you learned. Please write two paragraphs in which you report on Dr. Brown’s keynote presentation, including her topic, her primary argument, and what you learned.\n\n\n\nLightning Talk 1: Is the United Nations Security Council a Democratic Institution? Musings and Measures of Representation by Professor Amy Yuen\n\nemploys game theory and quanititvate analysis\n16 years at middlebury prof of political science\n\n15 members 5 permanent with veto power, all other elected no veto power\nUN security council voting rules favor the powerful # why do elected memebrs contineu to run for seats? what influence do they have?\nis the council a democratic institution? - the people speak to the government, would like to think international orgs are the same, but by the setup with the veto rules we can see that it is not equal or democractic, this is the structural instutional rules view - representation, who enagages in the council whose issues get attention? - measures resoultions, formal meeting and consulations, presidental statemnets…\nfindings\nsponsorship of brought up discussions - bigger chunk sitll peramenet meber but sitting elected is about half of box whisker plot\nwho serves on the council most? how long? - can be elected more than once - most frequent is japan, super active and give lots of money, then brazil - what would most and least inclusive councils look like? - tricky bc different amounts of seats in each region - finding of UN past was closer to the more inclusive line\nconclusions: democratic? no representative? could be worse what does this mean for output nad effectiveness? working on it, lots of ways to influence instituions\n\n\nLightning Talk 2: Beyond Deforestation: Monitoring Change in Tropical Forest Landscapes by Professor Jessica L’Roe\nlet go of gender expectations 1 undergrad female prof\nresearch themes: livelihoods, wellbeing, and land use in conservation hotspots survey landcover interview property data\nland regisration in brazil - in the amazon forest - property parsal data - remote sensing deforestation v good but couldnt figure out who was responsible - asked them to register property boundaries - people cheated and rounded down to be land smallholders so they wouldnt be held responsible for deforestation\nformalizing gold mining in peru - does formalizing it in one area discourage illegal mining in more sensitive areas? - no answer v brief\nlandscape changes around kibale national park, uganda - famous for primate diversity - population of smallholders farms increasing but why instead of increasing food production is there more tree planting?\nher job was on the ground, who is and why are they planting trees - brute force census did you have problems getting access to all of these plots or getting people to answer these questions - 60% something\nrelated problem as competition for land increase what will happen to local youth? - mothers investing in edjucation instead of land bc that was the safer bet, esp for girls\ngrace boyce lauren forrow all things can be data\n\n\nLighting Talk 3: Computational Linguistic Models of Mental Health By Professor Laura Biester\nconnection between lnaguague and mental health - computer used since 1980 to analyze languages for mental health classificaiotn 1st person pronounds used more by depressed people - topic of interest for NLP\nchallenge - access to high quality data - need to find a way to use publicly available data, relying on “self-reports” like “i was diagonozed with depression” - big data era with twitter reddit… - huge growth with size of datasets people are working with\n“pre-diagnosis data” - users who self report not representative of full pop with depression models built using datasets based on self-report don’t generlaize well\nhow to improve generalizaiton?\nfinding diagnosis dates - some self reports hint to when users got diagnosed\nneeded dataset to test generalization as well as large scale self-report based dataset collected own data\n360 json files usernames for self reports get those reddit posts then need posts from control users -&gt; got dataset 20.5k diagonsed used and 9 controls per diagoned user around 700 with identified diagnosis data\nsecond dataset uni michangan 32 depressed users, like 100 controls or somehting out of domain test dat a\nused logisitic regression and TFIDF classified with linear model\nthen used mentalBERT extract contextual representations of words\nprediagnosis models did well when compared to all alrge model\ncareful dtaa selction can be used to creat mro egenralizable linear models\nmodel weights for pre-diagnosis models correspond more to symtpoms while all models correpsond to mental health discussion\ndata collection is big big part not just abaout building models\n\n\nKeynote: Data Science Skills in Unexpected Places by Professor Sarah Brown\n\ncs prof at rhode island, machine learning director\n\nhow to look at machine leanring more fair, should be in toolbox to be more fair\nwhat is datascience? - venn diagram intersection of cs, stats, and domain expertise, but domain expertise shifts\nkey #1 - understanding data’s context - social studies - ptsd - grad school - discourse community of major - advanced writing class\nkey 2 accuracy doesn’t equal mistakenly denied bail, accuracy hard to define when not experts - disiplines are communities - just ask people\nkey 3 - national society of black energineers - meet people where they were\nbiased models still mkaing it out bc they are accuracy but need to meet people where they were\ncounts with histograms instead of fitted models\nmodel predictions may not always be the right\nthe hsitograms she did by the three statistcial measures of fiarness - not as strong tradeoffs for some reaosn - took those metrics and did them without model fitting in hisograms\nshe said have to let go of accuracy to get rid of data bias, cant\nhehe mentioned our article - what do you choose as your target variable? v important\n“law cant move as fast as code can” because law has to be socially negotiated\n\nReflection:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "CSCI 0451: Reflective Goal-Setting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWiDS Conference at Middlebury College\n\n\n\n\n\nBlog Post 3: Refelcting on and contextualizing the learning obtained from the Women in Data Science Conference\n\n\n\n\n\nMar 4, 2024\n\n\nJulia Joy\n\n\n\n\n\n\n\n\n\n\n\n\nDissecting Racial Bias\n\n\n\n\n\nBlog Post 2: Dissecting racial bias in an algorithm used to manage the health of populations\n\n\n\n\n\nFeb 29, 2024\n\n\nJulia Joy\n\n\n\n\n\n\n\n\n\n\n\n\nPalmer Penguins\n\n\n\n\n\nBlog Post 1: Palmer Penguins\n\n\n\n\n\nFeb 18, 2024\n\n\nJulia Joy\n\n\n\n\n\n\nNo matching items"
  }
]