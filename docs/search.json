[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi! My name is Julia Joy."
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/Blog1-Palmer Penguins/index.html",
    "href": "posts/Blog1-Palmer Penguins/index.html",
    "title": "Palmer Penguins",
    "section": "",
    "text": "The aim of this exploration of the Palmer Penguins dataset is to gain insight into the dataset through predictive classification. This exploration involves constructing visualizations of the data using seaborn and creating informative summary tables using pandas. By testing various combinations of models through a reproducible process, three key features are able to be identified. Out of the three features, I found that the combination of 1 qualitative feature: Clutch Completion, and 2 quantitative features: Culmen Length and Culmen Depth, were the most effective to reach 100% testing classification accuracy using a Decision Tree Model. The evaluation phase provides a visual representation of the models behavior by showing the decision regions of the trained decision tree model. Through this process, we gain a comprehensive understanding of the Palmer Penguins dataset and demonstrate the effectiveness of a trained decision tree model in accurately classifying Palmer Penguin data.\nimport pandas as pd\ntrain_url = “https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv” train = pd.read_csv(train_url)\nWe can take a peek at the data to get a better idea of where to start.\ntrain.head()"
  },
  {
    "objectID": "posts/Blog1-Palmer Penguins/index.html#figure-findings",
    "href": "posts/Blog1-Palmer Penguins/index.html#figure-findings",
    "title": "Palmer Penguins",
    "section": "Figure Findings",
    "text": "Figure Findings\nVarious summary tables and visualizations were tested, aiming to determine the most effective presentation of the Palmer Penguins dataset. Initially different grouping criteria and variables were considered, such as species, island, sex, clutch completion, culmen depth and length, body mass, and flipper length. Ultimately I decided to come back and choose the summary table and visualizations that reflected the variables I later found to have the highest predictive accuracy: Culmen Depth, Culmen Length, and Clutch Completion. Summary tables were created using pandas.groupby().aggregate. From the summary tables we observe that among different species, Culmen Length varies to a larger degree than Culmen Depth does. Upon a glance of the summary table, it is hard to see if clutch completion and culmen characteristics are correlated. In the first visualization on the right, we can see the penguins depicted by virtue of the respective culmen length and depth, colored by the Clutch Completion. We observe a relatively uniform distribution of clutch completion- there does not seem to be an immediate observable relationship between the three. My next visualization shows the same axes of Culmen Depth and Length, this time however colored by species. In this figure, we notice clear species groupings, corresponding to their Culmen Depth-Length relationship."
  },
  {
    "objectID": "posts/Blog1-Palmer Penguins/index.html#find-the-best-features-for-prediction",
    "href": "posts/Blog1-Palmer Penguins/index.html#find-the-best-features-for-prediction",
    "title": "Palmer Penguins",
    "section": "Find the Best Features for Prediction",
    "text": "Find the Best Features for Prediction\nIn order to ensure our model has the highest classification accuracy possible, we need to select features that are more indicative of the species group a penguin belongs to. By testing every combination of features, we are able to find the three that result in the highest training set accuracy. We find that there are multiple 3-feature sets with 100% training set classification accuracy.\n\nfrom itertools import combinations\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n# these are not actually all the columns: you'll \n# need to add any of the other ones you want to search for\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island\"]\nall_quant_cols = ['Flipper Length (mm)','Culmen Length (mm)', 'Culmen Depth (mm)']\n\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = qual_cols + list(pair) \n    print(cols)\n    # you could train models and score them here, keeping the list of \n    # columns for the model that has the best score. \n    #DT = DecisionTreeClassifier()\n    #DT.fit(X_train[cols], y_train)\n    #print(DT.score(X_train[cols], y_train))\n\nIn order to narrow these feature-sets down to the single set that will be the most effective and give us not only 100% training set classificaiton accuracy but also 100% testing set classification accuracy, we repeat the process from earlier. Now operating on the testing set, we narrow down the 3-feature sets into one final best feature set: Clutch Completion, Culmen Length (mm), and Culmen Depth (mm).\n\n#pretend we're numbering these from 1-9, look at testing accuracy for each one that has 1.0. \n\ntempCols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']\nDT = DecisionTreeClassifier()\nDT.fit(X_train[tempCols], y_train)\nprint(DT.score(X_train[tempCols], y_train))\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\nDT.score(X_test[tempCols], y_test)\n\n\n#1 0.97\n#2 nope\n#3 1.0 !!!  ['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n#4 0.97\n#5 nope\n#6 0.98\n#7 0.98\n#nope\n#9 0.98\n\nWe check our cross-validation score, noting that a cross validation score of 94.5% is indicitive of future model generalizability.\n\n#cross-validation\nfrom sklearn.model_selection import cross_val_score\ncv_scores_DT = cross_val_score(DT, X_train, y_train, cv=5)\ncv_scores_DT.mean()\n\n\nPlotting Decision Regions\nFinally, we can visualize these Decision Regions using matplotlib.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\n\n#visualizing decision regions on train set \nplot_regions(DT, X_train[keepCols], y_train)\n\n\n#visualizing decision regions on test set\nplot_regions(DT, X_test[keepCols], y_test)\n\n\n\nConfusion Matrix\n\n#need to truncate X_test to have only the columns we're using to predict before doing confusion matrix\nX_test = X_test[['Culmen Length (mm)', 'Culmen Depth (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']]\n\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = DT.predict(X_test)\ny_test_pred\n\nC = confusion_matrix(y_test, y_test_pred)\nC\n\nSince the trained model has 100% training and testing classifcation accuracy, the confusion matrix reflects the lack of classification errors.\n\n\nSummary Discussion\nIn conclusion, this exploration of the Palmer Penguins dataset has provided insights into the dataset through predictive classification. Through the construction of informative summary tables and visually appealing figures, we were able to uncover various patterns, trends, and relationships within the data. By systematically testing different combinations of both qualitative and quantitative features of the Palmer Penguins, I found the best combination of three features that yielded high classification accuracy. One qualitative feature, clutch completion, and two quantitative features, culmen length and culmen depth (mm). By employing scikit-learn’s DecisionTreeClassifier, I trained a model on these features and achieved a classification accuracy of 100% on both the training and testing sets. This shows the importance of feature selection, model selection and evaluation in building accurate predictive models. Through this whole process, I gained a comprehensive understanding of the Palmer Penguins dataset and demonstrate the effectiveness of a trained model in accurately classifying Palmer Penguin data. From this process, I learned how important both the selection of the right features as well as the right model are. I learned that 100% training set classification accuracy does not guarantee 100% testing set classification accuracy, and how it is important to tweak the model to ensure that future uses beyond a training set maintain a high level of accuracy. I gained an appreciation of visualizations as a tool for greater understanding of initial data as well as the effect of models. I feel confident in future endeavors to explore, visualize, and predict data."
  },
  {
    "objectID": "posts/Blog1-PalmerPenguins.html",
    "href": "posts/Blog1-PalmerPenguins.html",
    "title": "Palmer Penguins",
    "section": "",
    "text": "The aim of this exploration of the Palmer Penguins dataset is to gain insight into the dataset through predictive classification. This exploration involves constructing visualizations of the data using seaborn and creating informative summary tables using pandas. By testing various combinations of models through a reproducible process, three key features are able to be identified. Out of the three features, I found that the combination of 1 qualitative feature: Clutch Completion, and 2 quantitative features: Culmen Length and Culmen Depth, were the most effective to reach 100% testing classification accuracy using a Decision Tree Model. The evaluation phase provides a visual representation of the models behavior by showing the decision regions of the trained decision tree model. Through this process, we gain a comprehensive understanding of the Palmer Penguins dataset and demonstrate the effectiveness of a trained decision tree model in accurately classifying Palmer Penguin data.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\nWe can take a peek at the data to get a better idea of where to start.\n\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN"
  },
  {
    "objectID": "posts/Blog1-PalmerPenguins.html#figure-findings",
    "href": "posts/Blog1-PalmerPenguins.html#figure-findings",
    "title": "Palmer Penguins",
    "section": "Figure Findings",
    "text": "Figure Findings\nVarious summary tables and visualizations were tested, aiming to determine the most effective presentation of the Palmer Penguins dataset. Initially different grouping criteria and variables were considered, such as species, island, sex, clutch completion, culmen depth and length, body mass, and flipper length. Ultimately I decided to come back and choose the summary table and visualizations that reflected the variables I later found to have the highest predictive accuracy: Culmen Depth, Culmen Length, and Clutch Completion. Summary tables were created using pandas.groupby().aggregate. From the summary tables we observe that among different species, Culmen Length varies to a larger degree than Culmen Depth does. Upon a glance of the summary table, it is hard to see if clutch completion and culmen characteristics are correlated. In the first visualization on the right, we can see the penguins depicted by virtue of the respective culmen length and depth, colored by the Clutch Completion. We observe a relatively uniform distribution of clutch completion- there does not seem to be an immediate observable relationship between the three. My next visualization shows the same axes of Culmen Depth and Length, this time however colored by species. In this figure, we notice clear species groupings, corresponding to their Culmen Depth-Length relationship."
  },
  {
    "objectID": "posts/Blog1-PalmerPenguins.html#find-the-best-features-for-prediction",
    "href": "posts/Blog1-PalmerPenguins.html#find-the-best-features-for-prediction",
    "title": "Palmer Penguins",
    "section": "Find the Best Features for Prediction",
    "text": "Find the Best Features for Prediction\nIn order to ensure our model has the highest classification accuracy possible, we need to select features that are more indicative of the species group a penguin belongs to. By testing every combination of features, we are able to find the three that result in the highest training set accuracy. We find that there are multiple 3-feature sets with 100% training set classification accuracy.\n\nfrom itertools import combinations\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n# these are not actually all the columns: you'll \n# need to add any of the other ones you want to search for\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island\"]\nall_quant_cols = ['Flipper Length (mm)','Culmen Length (mm)', 'Culmen Depth (mm)']\n\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = qual_cols + list(pair) \n    print(cols)\n    # you could train models and score them here, keeping the list of \n    # columns for the model that has the best score. \n    #DT = DecisionTreeClassifier()\n    #DT.fit(X_train[cols], y_train)\n    #print(DT.score(X_train[cols], y_train))\n\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Flipper Length (mm)', 'Culmen Length (mm)']\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Flipper Length (mm)', 'Culmen Depth (mm)']\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n['Flipper Length (mm)', 'Culmen Length (mm)']\n['Flipper Length (mm)', 'Culmen Depth (mm)']\n['Culmen Length (mm)', 'Culmen Depth (mm)']\n['Flipper Length (mm)', 'Culmen Length (mm)']\n['Flipper Length (mm)', 'Culmen Depth (mm)']\n['Culmen Length (mm)', 'Culmen Depth (mm)']\n\n\nIn order to narrow these feature-sets down to the single set that will be the most effective and give us not only 100% training set classificaiton accuracy but also 100% testing set classification accuracy, we repeat the process from earlier. Now operating on the testing set, we narrow down the 3-feature sets into one final best feature set: Clutch Completion, Culmen Length (mm), and Culmen Depth (mm).\n\n#pretend we're numbering these from 1-9, look at testing accuracy for each one that has 1.0. \n\ntempCols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']\nDT = DecisionTreeClassifier()\nDT.fit(X_train[tempCols], y_train)\nprint(DT.score(X_train[tempCols], y_train))\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\nDT.score(X_test[tempCols], y_test)\n\n\n#1 0.97\n#2 nope\n#3 1.0 !!!  ['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n#4 0.97\n#5 nope\n#6 0.98\n#7 0.98\n#nope\n#9 0.98\n\n1.0\n\n\n1.0\n\n\nWe check our cross-validation score, noting that a cross validation score of 94.5% is indicitive of future model generalizability.\n\n#cross-validation\nfrom sklearn.model_selection import cross_val_score\ncv_scores_DT = cross_val_score(DT, X_train, y_train, cv=5)\ncv_scores_DT.mean()\n\n0.9452488687782805\n\n\n\nPlotting Decision Regions\nFinally, we can visualize these Decision Regions using matplotlib.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\n\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nClutch Completion_No\nClutch Completion_Yes\n\n\n\n\n0\n40.9\n16.6\nFalse\nTrue\n\n\n1\n49.0\n19.5\nFalse\nTrue\n\n\n2\n50.0\n15.2\nFalse\nTrue\n\n\n3\n45.8\n14.6\nFalse\nTrue\n\n\n4\n51.0\n18.8\nFalse\nTrue\n\n\n\n\n\n\n\n\n#visualizing decision regions on train set \nplot_regions(DT, X_train[keepCols], y_train)\n\n\n\n\n\n\n\n\n\n#visualizing decision regions on test set\nplot_regions(DT, X_test[keepCols], y_test)\n\n\n\n\n\n\n\n\n\n\nConfusion Matrix\n\n#need to truncate X_test to have only the columns we're using to predict before doing confusion matrix\nX_test = X_test[['Culmen Length (mm)', 'Culmen Depth (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']]\n\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = DT.predict(X_test)\ny_test_pred\n\nC = confusion_matrix(y_test, y_test_pred)\nC\n\n\narray([[31,  0,  0],\n       [ 0, 11,  0],\n       [ 0,  0, 26]])\n\n\nSince the trained model has 100% training and testing classifcation accuracy, the confusion matrix reflects the lack of classification errors.\n\n\nSummary Discussion\nIn conclusion, this exploration of the Palmer Penguins dataset has provided insights into the dataset through predictive classification. Through the construction of informative summary tables and visually appealing figures, we were able to uncover various patterns, trends, and relationships within the data. By systematically testing different combinations of both qualitative and quantitative features of the Palmer Penguins, I found the best combination of three features that yielded high classification accuracy. One qualitative feature, clutch completion, and two quantitative features, culmen length and culmen depth (mm). By employing scikit-learn’s DecisionTreeClassifier, I trained a model on these features and achieved a classification accuracy of 100% on both the training and testing sets. This shows the importance of feature selection, model selection and evaluation in building accurate predictive models. Through this whole process, I gained a comprehensive understanding of the Palmer Penguins dataset and demonstrate the effectiveness of a trained model in accurately classifying Palmer Penguin data. From this process, I learned how important both the selection of the right features as well as the right model are. I learned that 100% training set classification accuracy does not guarantee 100% testing set classification accuracy, and how it is important to tweak the model to ensure that future uses beyond a training set maintain a high level of accuracy. I gained an appreciation of visualizations as a tool for greater understanding of initial data as well as the effect of models. I feel confident in future endeavors to explore, visualize, and predict data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Palmer Penguins\n\n\n\n\n\nBlog Post 1: Palmer Penguins\n\n\n\n\n\nFeb 18, 2024\n\n\nJulia Joy\n\n\n\n\n\n\n\n\n\n\n\n\nPalmer Penguins\n\n\n\n\n\nBlog Post 1: Palmer Penguins\n\n\n\n\n\nFeb 18, 2024\n\n\nJulia Joy\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Post\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nHello Blog\n\n\n\n\n\nAn example blog post illustrating the key techniques you’ll need to demonstrate your learning in CSCI 0451.\n\n\n\n\n\nJan 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  }
]