[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi! My name is Julia Joy."
  },
  {
    "objectID": "posts/GoalSetting/index.html",
    "href": "posts/GoalSetting/index.html",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "Julia Joy\n\n\nThe knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nI think that the areas that i would most like to focus on are primarily the Implementation. I always feel like more practice with effective coding and learning how to use new tools is so invaluable, I am excited to continue that in this course, especially with all the different kinds of Machine Learning algorithms and models. I am also interested in the Theory aspect as a mathematics minor, I love learning about the numbers and formulas that go behind the operations we can take for granted when we code. I never took multi-calculus (I know, odd for a math minor), so while I think it will be a bit challenging to dredge up my calc and linear algebra since I took those courses so long ago, I think it will be rewarding and fun to expand my knowledge.\n\n\n\n\n\nMost blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\nI think blog posts will be pretty crucial to my learning in this course. Already with the first blog post and working on the second, I enjoy taking the content we discuss in class and applying it on my own. I have always felt like a hands-on learning style fits me the best. Ideally I would like to have a “Satisfactory/No Revision Required” rating on 5-6 of my of my blog posts, and perhaps completing more (I want to complete at least around 60-80% of blog posts) but leaving some space for some blog posts to remain in the “needs revision category”. I have realized that I am someone who is very driven by interest when it comes to coursework. Assignments I enjoy are fun little challenges for me, and I will spend hours working and tweaking them to my satisfiability even when they’re already probably pass the threshold of “good enough” grade wise. But assignments with content that I am not as passionate or interested about can be really hard for me to motivate to spend extra time on, so I would enjoy leaving some space for myself to say “no I think that is good enough for me. I tried it out and am satisfied with my work.”. I aim to give myself about 1-1.5 weeks for a fresh first-draft submission of each blog post I do, just to keep myself on a semi-timeline to ensure nothing gets crammed in at the end. With revision, I think that will be more dependent on extra time I have each week, spending more time on it in the weeks I have a bit more extra time and vice versa, I will allow myself less of a set timeline with those.\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\nI strive to attend every class, with the exception of one to two when it is truly necessary to miss class, such as if I’m sick, have to be out of town for some reason, or if my mental health gets in the way of my academics. In our two weeks of class, I have already gained an appreciation for the daily warmups. I find myself actually spending a good chunk of time on them before class, but I feel like it really does benefit me. The warmups prep me and lay a groundwork for either just basic understanding for the subject we tackle in that class, or in the application of what we’re about to talk about. I aim to complete every warmup prior to class this semester, with the leeway of one or two because life does happen. Outside of completing each warmup, whenever we are in our small groups, I aim to be very involved and ask questions and offer suggestions/solutions to whoever is the warmup presenter. I hope to complete most of the course readings, using it as more of a supplement to my hands on learning. Additionally, I notice that I frequently find it challenging to speak up in class, especially in a large class full of many people who are not only my peers but also my friends. The warmups in small groups help ease the transition before I potentially have to speak in front of the whole class. While I do still find it a bit intimidating, I really appreciate and value being able to talk the problems out in a smaller group setting before a larger one. Peer help/TA/office hours have long time been my favorite way to address questions or concepts I have a hard time grasping, so I expect to attend those when the need strikes. I have realized I am much more of a ask-questions-in-person kind of person than a slack questions user, so while I will check the slack and at some point probably use it to send a chat myself, I do not expect frequent use of it for myself. I think study groups will be big for me this semester, as I am familiar with many people in this course, so I think that will also be beneficial in my learning if I get stuck anywhere and help hours are immediately around.\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\nI am excited about this project as I feel like it will allow me to explore what machine learning can be in an area that I’m a bit more interested in, whatever that may be. Without knowing exactly what my project will look like or be about I cannot detail my goals in that way, however I know some general ideas of what I would like to accomplish. I would like to complete all project milestones on time to keep myself and the group accountable in our semester time frame, contribute to the project in an equal manner including in the algorithm implementation and project presentation, and do what I can to be a great group project partner. I think that everyone has strengths and weaknesses, and for example while I don’t think that I’m the best at writing automated checks for algorithms written by others, I have other skills to offer. I think that is the most important thing about working in a team, to acknowledge everyone’s weaknesses and capitalize on peoples strengths."
  },
  {
    "objectID": "posts/GoalSetting/index.html#what-youll-learn",
    "href": "posts/GoalSetting/index.html#what-youll-learn",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "The knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nI think that the areas that i would most like to focus on are primarily the Implementation. I always feel like more practice with effective coding and learning how to use new tools is so invaluable, I am excited to continue that in this course, especially with all the different kinds of Machine Learning algorithms and models. I am also interested in the Theory aspect as a mathematics minor, I love learning about the numbers and formulas that go behind the operations we can take for granted when we code. I never took multi-calculus (I know, odd for a math minor), so while I think it will be a bit challenging to dredge up my calc and linear algebra since I took those courses so long ago, I think it will be rewarding and fun to expand my knowledge."
  },
  {
    "objectID": "posts/GoalSetting/index.html#what-youll-achieve",
    "href": "posts/GoalSetting/index.html#what-youll-achieve",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "Most blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\nI think blog posts will be pretty crucial to my learning in this course. Already with the first blog post and working on the second, I enjoy taking the content we discuss in class and applying it on my own. I have always felt like a hands-on learning style fits me the best. Ideally I would like to have a “Satisfactory/No Revision Required” rating on 5-6 of my of my blog posts, and perhaps completing more (I want to complete at least around 60-80% of blog posts) but leaving some space for some blog posts to remain in the “needs revision category”. I have realized that I am someone who is very driven by interest when it comes to coursework. Assignments I enjoy are fun little challenges for me, and I will spend hours working and tweaking them to my satisfiability even when they’re already probably pass the threshold of “good enough” grade wise. But assignments with content that I am not as passionate or interested about can be really hard for me to motivate to spend extra time on, so I would enjoy leaving some space for myself to say “no I think that is good enough for me. I tried it out and am satisfied with my work.”. I aim to give myself about 1-1.5 weeks for a fresh first-draft submission of each blog post I do, just to keep myself on a semi-timeline to ensure nothing gets crammed in at the end. With revision, I think that will be more dependent on extra time I have each week, spending more time on it in the weeks I have a bit more extra time and vice versa, I will allow myself less of a set timeline with those.\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\nI strive to attend every class, with the exception of one to two when it is truly necessary to miss class, such as if I’m sick, have to be out of town for some reason, or if my mental health gets in the way of my academics. In our two weeks of class, I have already gained an appreciation for the daily warmups. I find myself actually spending a good chunk of time on them before class, but I feel like it really does benefit me. The warmups prep me and lay a groundwork for either just basic understanding for the subject we tackle in that class, or in the application of what we’re about to talk about. I aim to complete every warmup prior to class this semester, with the leeway of one or two because life does happen. Outside of completing each warmup, whenever we are in our small groups, I aim to be very involved and ask questions and offer suggestions/solutions to whoever is the warmup presenter. I hope to complete most of the course readings, using it as more of a supplement to my hands on learning. Additionally, I notice that I frequently find it challenging to speak up in class, especially in a large class full of many people who are not only my peers but also my friends. The warmups in small groups help ease the transition before I potentially have to speak in front of the whole class. While I do still find it a bit intimidating, I really appreciate and value being able to talk the problems out in a smaller group setting before a larger one. Peer help/TA/office hours have long time been my favorite way to address questions or concepts I have a hard time grasping, so I expect to attend those when the need strikes. I have realized I am much more of a ask-questions-in-person kind of person than a slack questions user, so while I will check the slack and at some point probably use it to send a chat myself, I do not expect frequent use of it for myself. I think study groups will be big for me this semester, as I am familiar with many people in this course, so I think that will also be beneficial in my learning if I get stuck anywhere and help hours are immediately around.\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\nI am excited about this project as I feel like it will allow me to explore what machine learning can be in an area that I’m a bit more interested in, whatever that may be. Without knowing exactly what my project will look like or be about I cannot detail my goals in that way, however I know some general ideas of what I would like to accomplish. I would like to complete all project milestones on time to keep myself and the group accountable in our semester time frame, contribute to the project in an equal manner including in the algorithm implementation and project presentation, and do what I can to be a great group project partner. I think that everyone has strengths and weaknesses, and for example while I don’t think that I’m the best at writing automated checks for algorithms written by others, I have other skills to offer. I think that is the most important thing about working in a team, to acknowledge everyone’s weaknesses and capitalize on peoples strengths."
  },
  {
    "objectID": "posts/DecisionMaking/index.html",
    "href": "posts/DecisionMaking/index.html",
    "title": "Dissecting Racial Bias",
    "section": "",
    "text": "Abstract\nThis exploratory analysis aims to replicate the primary findings of Obermeyer et al. in their study of ‘Dissecting racial bias in an algorithm used to manage the health of populations’ (2019). By reproducing various figures, such as Mean Number of Chronic Illnesses by Percentile Risk Score and Total Medical Expenditure vs. Number of Chronic Illnesses, as well as fitting a linear regression model, this analysis aims to determine if there exists substansial disparity between the risk score and medical costs incurred of black and white patients. The findings indicate that there does indeed exists a disparity between both the attributed risk score and the medical costs incurred of the patients by race. The risk score of white patients are higher than their black patient counterparts who have the same number of chronic illnesses. The costs follow a similar pattern, where white patients incur greater medical costs than their black patient counterparts who have the same number of chronic illnesses. Black patients incur approximately 75% of the costs that white patients incur. These finding suggest that black patients are not getting the health care they need, as they are deprioritized with lower risk scores and receiving less needed healthcare as they take on less medical costs.\n\n\nPART A: Data Access\nLoading in the data, I take a preliminary view to understand the meaning of the respective rows and columns.\n\n# load data \nimport pandas as pd\nurl = \"https://gitlab.com/labsysmed/dissecting-bias/-/raw/master/data/data_new.csv?inline=false\"\ndf = pd.read_csv(url)\n\n/var/folders/6v/npbkg9_919s0m2j5qd702gf00000gn/T/ipykernel_10168/3568355658.py:2: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\nrisk_score_t\nprogram_enrolled_t\ncost_t\ncost_avoidable_t\nbps_mean_t\nghba1c_mean_t\nhct_mean_t\ncre_mean_t\nldl_mean_t\nrace\n...\ntrig_min-high_tm1\ntrig_min-normal_tm1\ntrig_mean-low_tm1\ntrig_mean-high_tm1\ntrig_mean-normal_tm1\ntrig_max-low_tm1\ntrig_max-high_tm1\ntrig_max-normal_tm1\ngagne_sum_tm1\ngagne_sum_t\n\n\n\n\n0\n1.987430\n0\n1200.0\n0.0\nNaN\n5.4\nNaN\n1.110000\n194.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n7.677934\n0\n2600.0\n0.0\n119.0\n5.5\n40.4\n0.860000\n93.0\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n4\n3\n\n\n2\n0.407678\n0\n500.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0.798369\n0\n1300.0\n0.0\n117.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n17.513165\n0\n1100.0\n0.0\n116.0\nNaN\n34.1\n1.303333\n53.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n\n\n\n\n5 rows × 160 columns\n\n\n\n\n\nPART B: Reproducing Figure 1\n\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n\nblackDF= df[df[\"race\"] == \"black\"].copy()\nblackDF['risk_percentile'] = (df['risk_score_t'].rank(pct=True) * 100).round()\nmeanCCblack = blackDF.groupby('risk_percentile')['gagne_sum_t'].transform('mean')\nblackDF['meanCCblack'] = meanCCblack\n\n \nwhiteDF = df[df[\"race\"] == \"white\"].copy()\nwhiteDF['risk_percentile'] = (df['risk_score_t'].rank(pct=True) * 100).round()\nmeanCCwhite = whiteDF.groupby('risk_percentile')['gagne_sum_t'].transform('mean')\nwhiteDF['meanCCwhite'] = meanCCwhite\n\n\n\nsns.scatterplot(x='meanCCblack', y='risk_percentile', data=blackDF, color='teal', label='Black')\nsns.scatterplot(x='meanCCwhite', y='risk_percentile', data=whiteDF, color='orange', label='White')\n\nplt.xlabel('Mean Number of Chronic Illnesses by Percentile Risk Score')\nplt.ylabel('Percentile Risk Score')\nplt.title('Mean Number of Chronic Illnesses')\nplt.legend(title='Race')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nAs we see from the plot, Patient A and Patient B are not equally likely to be referred to the high-risk care management program. Given the same number of active chronic conditions, white patients tend to score higher risk scores compared to their black counterparts. Thus white patients, such as patient A would be more likely to be referred to the high-risk care management program than black patients such as patient B. As Obermeyer et al said, “less-healthy Blacks scored at similar risk scores to more-healthy Whites” and thus there is evidence for “substantial disparities” in the program.\n\n\nPART C: Reproducing Figure 3\n\ndf['risk_percentile'] = (df['risk_score_t'].rank(pct=True) * 100).round()\nriskCostDF = df.groupby(['risk_percentile','race']).aggregate({'cost_t': 'mean'}).reset_index()\n\n\n\nsns.scatterplot(x='risk_percentile', y='cost_t', hue = 'race', data=riskCostDF)\nplt.xlabel('Percentile Risk Score')\nplt.ylabel('Total Medical Expenditure')\nplt.title('Total Medical Expenditure vs. Percentile Risk Score')\nplt.grid(True)\nplt.yscale('log')\nplt.show()\n\n\n\n\n\n\n\n\n\nblackDF = df[df[\"race\"] == \"black\"].copy()\nwhiteDF = df[df[\"race\"] == \"white\"].copy()\n\nchronicCostBlack = blackDF.groupby('gagne_sum_t')['cost_t'].mean().reset_index()\nchronicCostWhite = whiteDF.groupby('gagne_sum_t')['cost_t'].mean().reset_index()\n\nsns.scatterplot(x='gagne_sum_t', y='cost_t', data=chronicCostBlack, label =\"White\")\nsns.scatterplot(x='gagne_sum_t', y='cost_t', data=chronicCostWhite, label =\"Black\")\nplt.xlabel('Number of Chronic Illnesses')\nplt.ylabel('Total Medical Expenditure')\nplt.title('Total Medical Expenditure vs. Number of Chronic Illnesses')\nplt.legend(title='Race')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFrom the reproduction of these two figures, we can better understand our data. We note that a vast majority of patients in this data set have 5 or fewer chronic conditions. A surprising finding that there exists more disparity in health conditional risk than in costs. However, black patients have lower costs on average than their white patient counterparts, potentially suggesting they are not getting the care they need. To accurately predict costs for patients, their race is crucial information as it distinguishes their predicted costs, this suggests that the relationship between the number of chronic conditions and the cost might be nonlinear.\n\n\nPART D: Modeling Cost Disparity\n\nCostDisparityDF = df[df['gagne_sum_t'] &lt;= 5]\nfiveChronics = CostDisparityDF.shape[0]\ntotalPatientsNum = df.shape[0]\npercentFiveChronics = (fiveChronics / totalPatientsNum) * 100\n\nAbout 95 percent of patients have five or less chronic conditions. Since this is the vast majority of patients, it is justified to focus in on these patients\n\nCostDisparityDF = CostDisparityDF[CostDisparityDF['cost_t'] &gt; 0]\nCostDisparityDF['logCost'] = np.log(CostDisparityDF['cost_t'])\n\nCostDisparityDF['OneHotRace'] = (CostDisparityDF['race'] == 'black').astype(int)\n\n#separate into predictor variables and target variable \npredictorX = CostDisparityDF[['OneHotRace', 'gagne_sum_t']]\ntargetY = CostDisparityDF['logCost']\n\n\n\ntargetY\n\n0        7.090077\n1        7.863267\n2        6.214608\n3        7.170120\n4        7.003065\n           ...   \n48779    6.684612\n48780    7.696213\n48781    6.684612\n48782    7.170120\n48783    8.389360\nName: logCost, Length: 44748, dtype: float64\n\n\nAs indicated in the findings from my figures above, the relationship between the number of chronic conditions and the cost might be nonlinear. Thus in order to fit a linear regression model, we must fit the model with a certain number of polynomial features of active chronic condition in order to to account for the nonlinearity. To determine how many polynomial features should be used for best predictions on this data set, cross validation is needed to test various data sets with differing number of polynomial feature sizes. For each possible polynomial feature size, a LinearRegression model is constructed a cross validation score is computed.\n\ndef add_polynomial_features(X, degree):\n  X_ = X.copy()\n  for j in range(1, degree):\n    X_[f\"poly_{j}\"] = X_[\"gagne_sum_t\"]**j\n  return X_\n\n\nfrom sklearn.linear_model import LinearRegression as LR\nfrom sklearn.model_selection import cross_val_score\n#test each num of active chronic conditions \ncvScores = []\n\nfor degree in range (1,6):\n    X_poly = add_polynomial_features(predictorX, degree)\n    modelToEvaluate = LR()\n    scores = cross_val_score(modelToEvaluate, X_poly, targetY, cv=5, scoring='explained_variance')\n    cvScores.append(np.mean(scores))\n\n    modelToEvaluate.fit(X_poly, targetY)\n\n\ncvScores\n\n[0.08547350567418092,\n 0.0854752316405665,\n 0.0862993008389995,\n 0.08704835621632338,\n 0.08740844467965052]\n\n\n\n#fit the one that is best \npredictorX = add_polynomial_features(predictorX,6)\nfinalModel = LR()\nfinalModel.fit(predictorX, targetY)\nfinalModel.coef_\n\narray([-0.2827181 ,  0.5939195 ,  0.5939195 , -1.28588299,  0.65937337,\n       -0.14306628,  0.01107307])\n\n\nOnce the size of the polynomial feature that is most resonable for this dataset is determined, I fit one last linear regression model with the correct number of polynomial features, which in this case, is all 5.\n\ncostIncurred = np.exp(finalModel.coef_[0])\ncostIncurred\n#0.75\n\n0.7537322331638742\n\n\nFinally, e^W(b) is computed, which represents the cost incurred by black patients as a percentage of white patients. We find this number to be 0.75, which means that black patients incur 75% of the cost that white patients incur. This finding does indeed roughly support the argument of Obermeyer et al. (2019), as Obermeyer et al. claimed that there were opportunites for a disparity wedge to occur between needing health care and receiving health care, claiming that this disparity wedge was found to be correlated with race. Our findings indicate the same thing, since the interpretation of our 75% cost incurred figure could mean that a black patient with the same amount of chronic illnesses as a white patient would be paying less (and thus assumed to be receiving less needed healthcare).\n\n\nPart E: Discussion\nThroughout this exploratory analysis that aimed to replicate the primary findings of Obermeyer et al. in their study of ‘Dissecting racial bias in an algorithm used to manage the health of populations’ (2019), we find similar results and conclusions. By contructing plot figures and linear regression models, I learned that there does indeed exists a disparity between both the attributed risk score and the medical costs incurred of the patients by race. The risk score of white patients are higher than their black patient counterparts who have the same number of chronic illnesses. The costs follow a similar pattern, bBlack patients incurring approximately 75% of the costs that white patients incur, where both sets of patient counterparts have the same number of chronic illnesses. These finding suggest that black patients are not getting the health care they need, as they are deprioritized with lower risk scores and receiving less needed healthcare as they take on less medical costs. The importance of constructing a linear regression model with the proper number of polynomial features was emphasized in this analysis. Additionally, I gained an appreciation for extrapolating findings beyond their face value. Black patients incur less medical costs than their white counterparts with the same number of chronic illnesses. Why? Perhaps because they are not receiving the full extent of the healthcare they need and are thus paying less medical costs.\nWhat aspects of the study support your answer?\nOf the three statistical discrimation criteria discussed in Chapter 3 of Barocas, Hardt, and Narayanan (2023)- error rate parity, acceptance rate parity/independence, and sufficiency (calibration), the criteria that best describes the purported bias of the algorithm studied by Obermeyer et al. (2019) is error rate parity. I believe that error rate parity best describes the purported bias of the algorithm because the algorithm systematically assigns lower risk scores to black patients compared to white patients with the same number of chronic illnesses which can/does lead to unequal treatment and resource allocation in healthcare. The aspects of the study that support my answer is Obermeyer et al.’s commentary that this bias is “attributable to label choice—the difference between some unobserved optimal prediction and the prediction of an algorithm trained on an observed label”. They claim that labels can be often measured in an error-prone way that reflect structural inequalities. This model has a problem with error rate parity as it does not make errors at similar rates for different groups to ensure fairness."
  },
  {
    "objectID": "posts/Palmer Penguins/index.html",
    "href": "posts/Palmer Penguins/index.html",
    "title": "Palmer Penguins",
    "section": "",
    "text": "The aim of this exploration of the Palmer Penguins dataset is to gain insight into the dataset through predictive classification. This exploration involves constructing visualizations of the data using seaborn and creating informative summary tables using pandas. By testing various combinations of models through a reproducible process, three key features are able to be identified. Out of the three features, I found that the combination of 1 qualitative feature: Clutch Completion, and 2 quantitative features: Culmen Length and Culmen Depth, were the most effective to reach 100% testing classification accuracy using a Decision Tree Model. The evaluation phase provides a visual representation of the models behavior by showing the decision regions of the trained decision tree model. Through this process, we gain a comprehensive understanding of the Palmer Penguins dataset and demonstrate the effectiveness of a trained decision tree model in accurately classifying Palmer Penguin data.\nimport pandas as pd\ntrain_url = “https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv” train = pd.read_csv(train_url)\nWe can take a peek at the data to get a better idea of where to start, by using .head()\ntrain.head()"
  },
  {
    "objectID": "posts/Palmer Penguins/index.html#figure-findings",
    "href": "posts/Palmer Penguins/index.html#figure-findings",
    "title": "Palmer Penguins",
    "section": "Figure Findings",
    "text": "Figure Findings\nVarious summary tables and visualizations were tested, aiming to determine the most effective presentation of the Palmer Penguins dataset. Initially different grouping criteria and variables were considered, such as species, island, sex, clutch completion, culmen depth and length, body mass, and flipper length. Ultimately I decided to come back and choose the summary table and visualizations that reflected the variables I later found to have the highest predictive accuracy: Culmen Depth, Culmen Length, and Clutch Completion. Summary tables were created using pandas.groupby().aggregate. From the summary tables we observe that among different species, Culmen Length varies to a larger degree than Culmen Depth does. Upon a glance of the summary table, it is hard to see if clutch completion and culmen characteristics are correlated. In the first visualization on the right, we can see the penguins depicted by virtue of the respective culmen length and depth, colored by the Clutch Completion. We observe a relatively uniform distribution of clutch completion- there does not seem to be an immediate observable relationship between the three. My next visualization shows the same axes of Culmen Depth and Length, this time however colored by species. In this figure, we notice clear species groupings, corresponding to their Culmen Depth-Length relationship."
  },
  {
    "objectID": "posts/Palmer Penguins/index.html#find-the-best-features-for-prediction",
    "href": "posts/Palmer Penguins/index.html#find-the-best-features-for-prediction",
    "title": "Palmer Penguins",
    "section": "Find the Best Features for Prediction",
    "text": "Find the Best Features for Prediction\nIn order to ensure our model has the highest classification accuracy possible, we need to select features that are more indicative of the species group a penguin belongs to. By testing every combination of features, we are able to find the three that result in the highest training set accuracy. We find that there are multiple 3-feature sets with 100% training set classification accuracy.\n\nfrom itertools import combinations\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n# these are not actually all the columns: you'll \n# need to add any of the other ones you want to search for\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island\"]\nall_quant_cols = ['Flipper Length (mm)','Culmen Length (mm)', 'Culmen Depth (mm)']\n\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = qual_cols + list(pair) \n    print(cols)\n    # you could train models and score them here, keeping the list of \n    # columns for the model that has the best score. \n    #DT = DecisionTreeClassifier()\n    #DT.fit(X_train[cols], y_train)\n    #print(DT.score(X_train[cols], y_train))\n\nIn order to narrow these feature-sets down to the single set that will be the most effective and give us not only 100% training set classificaiton accuracy but also 100% testing set classification accuracy, we repeat the process from earlier. Now operating on the testing set, we narrow down the 3-feature sets into one final best feature set: Clutch Completion, Culmen Length (mm), and Culmen Depth (mm).\n\n#pretend we're numbering these from 1-9, look at testing accuracy for each one that has 1.0. \n\ntempCols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']\nDT = DecisionTreeClassifier()\nDT.fit(X_train[tempCols], y_train)\nprint(DT.score(X_train[tempCols], y_train))\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\nDT.score(X_test[tempCols], y_test)\n\n\n#1 0.97\n#2 nope\n#3 1.0 !!!  ['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n#4 0.97\n#5 nope\n#6 0.98\n#7 0.98\n#nope\n#9 0.98\n\nWe check our cross-validation score, noting that a cross validation score of 94.5% is indicitive of future model generalizability.\n\n#cross-validation\nfrom sklearn.model_selection import cross_val_score\ncv_scores_DT = cross_val_score(DT, X_train, y_train, cv=5)\ncv_scores_DT.mean()\n\n\nPlotting Decision Regions\nFinally, we can visualize these Decision Regions using matplotlib.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\n\n#visualizing decision regions on train set \nplot_regions(DT, X_train[keepCols], y_train)\n\n\n#visualizing decision regions on test set\nplot_regions(DT, X_test[keepCols], y_test)\n\n\n\nConfusion Matrix\n\n#need to truncate X_test to have only the columns we're using to predict before doing confusion matrix\nX_test = X_test[['Culmen Length (mm)', 'Culmen Depth (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']]\n\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = DT.predict(X_test)\ny_test_pred\n\nC = confusion_matrix(y_test, y_test_pred)\nC\n\nSince the trained model has 100% training and testing classifcation accuracy, the confusion matrix reflects the lack of classification errors.\n\n\nSummary Discussion\nIn conclusion, this exploration of the Palmer Penguins dataset has provided insights into the dataset through predictive classification. Through the construction of informative summary tables and visually appealing figures, we were able to uncover various patterns, trends, and relationships within the data. By systematically testing different combinations of both qualitative and quantitative features of the Palmer Penguins, I found the best combination of three features that yielded high classification accuracy. One qualitative feature, clutch completion, and two quantitative features, culmen length and culmen depth (mm). By employing scikit-learn’s DecisionTreeClassifier, I trained a model on these features and achieved a classification accuracy of 100% on both the training and testing sets. This shows the importance of feature selection, model selection and evaluation in building accurate predictive models. Through this whole process, I gained a comprehensive understanding of the Palmer Penguins dataset and demonstrate the effectiveness of a trained model in accurately classifying Palmer Penguin data. From this process, I learned how important both the selection of the right features as well as the right model are. I learned that 100% training set classification accuracy does not guarantee 100% testing set classification accuracy, and how it is important to tweak the model to ensure that future uses beyond a training set maintain a high level of accuracy. I gained an appreciation of visualizations as a tool for greater understanding of initial data as well as the effect of models. I feel confident in future endeavors to explore, visualize, and predict data."
  },
  {
    "objectID": "posts/WIDS Conference/index.html",
    "href": "posts/WIDS Conference/index.html",
    "title": "WiDS Conference at Middlebury College",
    "section": "",
    "text": "In this blog post, I reflect on my experiences reading ‘Solving the Equation: The Variables for Women’s Success in Engineering and Computing’ by Corbett and Hill (2015) and attending the Women in Data Science conference. Through the two of these experiences, I gained valuable insights into the challenges and potential solutions surrounding gender diversity in STEM fields. I learned about the systemic barriers that hinder women’s ability to enter, continue, and succeed in engineering and computing, that highlight the importance of proactive strategies to equalize representation of women in STEM. This blog post outlines these learnings by reflecting on questions from ‘Solving the Equation: The Variables for Women’s Success in Engineering and Computing’ as well as summarizing the speakers from the Women in Data Science conference."
  },
  {
    "objectID": "posts/WIDS Conference/index.html#part-1-why-spotlight-women-in-data-science",
    "href": "posts/WIDS Conference/index.html#part-1-why-spotlight-women-in-data-science",
    "title": "WiDS Conference at Middlebury College",
    "section": "Part 1: Why Spotlight Women in Data Science?",
    "text": "Part 1: Why Spotlight Women in Data Science?\nIn ‘Solving the Equation: The Variables for Women’s Success in Engineering and Computing’ by Corbett and Hill (2015), the authors show that women are underrepresented in computing, math, and engineering. But why is it a problem? And for whom is it a problem?\nThis underrepresentation of women significant challenges on multiple fronts. This underrepresentation reflects systemic inequalities and biases that have been shown to hinder equal opportunities for women in these fields. By not teaching everyone that women can hold their own and be equally as good in STEM fields as men, women lose out on these high-quality job opportunities. This is not just a problem for women. By a lack of women in computing, math, and engineering, it not only deprives women of potential career paths, but it also limits the diversity of perspectives and talents that are crucial for solving problems, developing rounded mechanisms, and field innovation. As Corbet and Hill said, “The United States simply can’t afford to ignore the perspectives of half the population in future engineering and technical designs”. Gender biases that contribute to the underrepresentation of women in computing, math, and engineering also create obstacles for the men who work alongside women in these industries. Studies point to a devaluation of work when men work with women (West et al., 2012), which can lead to men traking steps to avoid wokring with women, worsening the challenges facing women in male-dominated fields and contributing to the problem. Everyone must work together to help balance the gender representation in computing, math, and engineering, as it is a problem that affects us all no matter our identity.\n\nWhich of the barriers and unequal challenges described in the section “Why So Few?” can be eroded by events that spotlight the achievement of women in STEM?\nThe section “Why so Few?” outlines various barriers and unequal challenges women face in the STEM field, such as sense of belonging, stereotypes and stereotype threat, challenging academic workspaces, as well as isolation. Women may face negative impacts such as experiencing difficultly balancing expected gendered home responsibilities and the culture of overwork, feel de-incentivized by the engineering culture of disengagement as studies show women are more likely than men to express a preference for work with a clear social purpose (Konrad et al., 2000), or feel isolated as significant portion of women reported feeling as if they lacked role models and mentors and did not agree with the statement that “it is safe to speak up most of the time”. While not all of these barriers or challenges can be eroded by events that spotlight the achievement of women in STEM, there are a few that can benefit from these events. What stood out most notably to me that could be benefited by these events was improving the sense of belonging for women in STEM. Events that spotlight the achievement of women in STEM can help increase the sense of belonging for women in STEM, and can have a positive domino-effect in doing so. Events that spotlight the achievement of women in STEM shows examples of women in a historically male-dominated field, helping combat both internalized and external stereotypes. These events show women that success in STEM is possible, providing role models and mentors, which was also noted as a problem for women in the industry. Achievement spotlight events are thus crucial for increasing women’s sense of belonging and increasing the number of women in STEM.\n\n\nPart 2: Attending the Women in Data Science Conference. Yay!\nBy attending the Women in Data Science Conference, I had an unique opportunity to engage with and hear from real professional women that have succeeded against all of the challenges in a male-dominated field, learning about their work as well as their experiences."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "CSCI 0451: Reflective Goal-Setting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWiDS Conference at Middlebury College\n\n\n\n\n\nBlog Post 3: Refelcting on and contextualizing the learning obtained from the Women in Data Science Conference\n\n\n\n\n\nMar 4, 2024\n\n\nJulia Joy\n\n\n\n\n\n\n\n\n\n\n\n\nDissecting Racial Bias\n\n\n\n\n\nBlog Post 2: Dissecting racial bias in an algorithm used to manage the health of populations\n\n\n\n\n\nFeb 29, 2024\n\n\nJulia Joy\n\n\n\n\n\n\n\n\n\n\n\n\nPalmer Penguins\n\n\n\n\n\nBlog Post 1: Palmer Penguins\n\n\n\n\n\nFeb 18, 2024\n\n\nJulia Joy\n\n\n\n\n\n\nNo matching items"
  }
]